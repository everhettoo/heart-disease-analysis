{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "As explained in [01.data-introduction](01.data-introduction.ipynb), the author (Dr. Roberto Detrano) intended to build a model to predict heart disease using the 13 variables and 1 target variable. He used cleveland dataset to build the model and predict against other datasets. The datasets are explained in the table below:\n",
    "\n",
    "| Filename                   | Records (Rows) | Features (Cols) | Description                 |\n",
    "|:---------------------------|:--------------:|:---------------:|:----------------------------|\n",
    "| processed.cleveland.data   |      303       |       14        | Used for building the model |\n",
    "| processed.hungarian.data   |      294       |       14        | Used for testing            |\n",
    "| processed.va.data          |      200       |       14        | Used for testing            |\n",
    "| processed.switzerland.data |      123       |       14        | Used for testing            |\n",
    "\n",
    "## Data Dictionary\n",
    "In the processed datasets (as described in [01.data-introduction](01.data-introduction.ipynb)), the author has mapped the following variables from the original (raw) dataset to processed dataset for building the model. Please find the <u>data dictionary for the processed dataset that is used in this study</u>.\n",
    "| No  | Name         | Description                                              | Values                                                                                                                              |\n",
    "|:----|:-------------|:---------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 1.  | age          | age in years                                             |                                                                                                                                     |\n",
    "| 2.  | sex          | sex                                                      | 1: male <br> 0: female                                                                                                              |\n",
    "| 3.  | cp           | chest pain type                                          | 1: typical angina <br> 2: atypical angina <br> 3: non-anginal pain <br> 4: asymptomatic                                             |\n",
    "| 4.  | trestbps     | systolic blood pressure at rest (in mm Hg)               |                                                                                                                                     |\n",
    "| 5.  | chol         | serum cholesterol in mg/dl                               |                                                                                                                                     |\n",
    "| 6.  | fbs          | fasting blood sugar > 120 mg/dl                          | 1: true <br> 0: false                                                                                                               |\n",
    "| 7.  | restecg      | resting electrocardiographic results                     | 0: normal <br> 1: having ST-T wave abnormality <br> 2: showing probable or definite left ventricular hypertrophy by Estes' criteria |\n",
    "| 8.  | thalach      | maximum heart rate achieved                              |                                                                                                                                     |\n",
    "| 9.  | exang        | exercise induced angina                                  | 1: yes <br> 0: no                                                                                                                   |\n",
    "| 10. | oldpeak      | ST depression induced by exercise relative to rest       |                                                                                                                                     |\n",
    "| 11. | slope        | the slope of the peak exercise ST segment                | 1: upsloping <br> 2: flat <br> 3: downsloping                                                                                       |\n",
    "| 12. | ca           | number of major vessels (0-3) colored by fluoroscopy     |                                                                                                                                     |\n",
    "| 13. | thal         |                                                          | 3: normal <br> 6: fixed defect <br> 7: reversable defect                                                                            |\n",
    "| 14. | num (target) | diagnosis of heart disease (angiographic disease status) | 0: < 50% diameter narrowing <br> 1: > 50% diameter narrowing                                                                        |"
   ],
   "id": "6b5b0cfff891869d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The Objective\n",
    "In attempts to build ML models using the heart-disease dataset, the following questions needs clarification in this stage (data exploration).\n",
    "1. What problem needs to be solved?\n",
    "2. Does the dataset have duplicate rows (records)?\n",
    "3. What data-types the dataset contains?\n",
    "4. Does the dataset have empty columns (features)?\n",
    "5. Is the dataset sufficient for building the model(s)?\n",
    "6. Which feature appears more important than the other?\n",
    "\n",
    "Once, these questions are clarified, a list of action items can help for next stage."
   ],
   "id": "f0eb4ade433a0269"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's load the necessary libraries and data for investigation.",
   "id": "9a9a9d5e14e695d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:03:08.680427Z",
     "start_time": "2024-12-17T11:02:47.267117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# All required libraries.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt;\n",
    "import seaborn as sns;\n",
    "from custom_libs import helper\n",
    "from importlib import reload\n",
    "import numpy as np"
   ],
   "id": "8f21e87a43621955",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "890749f0a123e02b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:09:58.251359Z",
     "start_time": "2024-12-17T11:09:58.243709Z"
    }
   },
   "source": [
    "filename = \"switzerland\"\n",
    "header =['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "data = pd.read_csv(f'data/uci-heart-disease/processed.{filename}.data', names=header)\n",
    "# 303 records and 14 columns.\n",
    "data.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age  sex  cp trestbps  chol fbs restecg thalach exang oldpeak slope ca  \\\n",
       "0   32    1   1       95     0   ?       0     127     0      .7     1  ?   \n",
       "1   34    1   4      115     0   ?       ?     154     0      .2     1  ?   \n",
       "2   35    1   4        ?     0   ?       0     130     1       ?     ?  ?   \n",
       "3   36    1   4      110     0   ?       0     125     1       1     2  ?   \n",
       "4   38    0   4      105     0   ?       0     166     0     2.8     1  ?   \n",
       "\n",
       "  thal  num  \n",
       "0    ?    1  \n",
       "1    ?    1  \n",
       "2    7    3  \n",
       "3    6    1  \n",
       "4    ?    2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>.7</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>.2</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. What problem needs to be solved?\n",
    "<b>Classify</b> - whether a patient has heart disease based on his/her medical data.\n",
    "\n",
    "At a glance, it appears to be binary classification problem.\\\n",
    "From the data-dictionary, `num` appears as the target variable. Let's investigate the target variable's supportability for <u>binary classification</u> problem."
   ],
   "id": "322ef85552d321e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:10:02.555175Z",
     "start_time": "2024-12-17T11:10:02.550658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Target variable (num) has integer data-type.\n",
    "data.info()"
   ],
   "id": "cc0d8512f6a6ebce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123 entries, 0 to 122\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   age       123 non-null    int64 \n",
      " 1   sex       123 non-null    int64 \n",
      " 2   cp        123 non-null    int64 \n",
      " 3   trestbps  123 non-null    object\n",
      " 4   chol      123 non-null    int64 \n",
      " 5   fbs       123 non-null    object\n",
      " 6   restecg   123 non-null    object\n",
      " 7   thalach   123 non-null    object\n",
      " 8   exang     123 non-null    object\n",
      " 9   oldpeak   123 non-null    object\n",
      " 10  slope     123 non-null    object\n",
      " 11  ca        123 non-null    object\n",
      " 12  thal      123 non-null    object\n",
      " 13  num       123 non-null    int64 \n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 13.6+ KB\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T11:10:04.628648Z",
     "start_time": "2024-12-17T11:10:04.625493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Target variable (num) has more than two values/classes. Meanwhile, binary classification requires only 2 values/classes.\n",
    "data['num'].value_counts()"
   ],
   "id": "e25a1afb0b274595",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "1    48\n",
       "2    32\n",
       "3    30\n",
       "0     8\n",
       "4     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observation:\n",
    "The target variable (num) cannot support binary classification since it has more than 2 values/classes. \\\n",
    "If we understood the original intention from the data-dictionary and the literature:\n",
    "- Any patient with less than 50% vessel narrowing was marked as `value: 0` -- no heart disease\n",
    "- Any patient with more than 50% vessel narrowing was marked as `value: 1` -- has heart disease. This was further expanded to 1, 2, 3 and 4 based on affected major vessel.\n",
    "\n",
    "### Conclusion:\n",
    "We <u>can safely convert this to a binary classification problem</u> by replacing any values of target variable (num) other than `0` to `1`. This logically simplifies that any patient with vessel narrowing more than 50% is suspected to have heart-disease (without distorting the original meaning much).\n",
    "\n",
    "### Action(s)\n",
    "1. Convert any values in target variable (num) other than `0` to `1` - to support binary classification problem.\n",
    "2. Also, rename the target variable from `num` to `target` to give a more meaningful name."
   ],
   "id": "20a1761f4ac8c562"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Convert any values in target variable (num) other than `0` to `1` - to support binary classification problem.\n",
    "# Let's see the count before conversion\n",
    "data['num'].value_counts()"
   ],
   "id": "cd010bc96be740b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see if the sum of 1, 2, 3 and 4 has total up to 55 + 36 + 35 + 13 = 139.\n",
    "data.loc[data['num']!=0,\"num\"]=1\n",
    "data['num'].value_counts()"
   ],
   "id": "4d29b68f7f6e02cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2. Also, rename the target variable from `num` to `target` to give a more meaningful name.\n",
    "data.rename(columns={'num':'target'}, inplace=True)"
   ],
   "id": "d75fd6df4eb67d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The new 'target' column tallies with the old 'num' column.\n",
    "data['target'].value_counts()"
   ],
   "id": "3b6b718bc8b4bf6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Does the dataset have duplicate rows (records)?\n",
    "So, we converted the target variable from multi-class to binary to support binary classification problem. \\\n",
    "Now, let's investigate if any duplicate records (rows) present in the dataset."
   ],
   "id": "525c3df77669b28e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# All columns were checked, and no duplicate record found.\n",
    "data[data.duplicated()]"
   ],
   "id": "d430b6044ff55447",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. What data-types the dataset contains?\n",
    "We got the basic idea about the data types from the 'data-dictionary'. let's investigate and verify further the content."
   ],
   "id": "14e49292b4c2276e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.info()",
   "id": "24c19fe43fa345cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All features appears to be in numerical format except for `ca` and `thal`. They appear to be categorical from 'data-dictionary'. Let's investigate further.",
   "id": "f32bc124eb443b99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For column 'ca', 4 records contains the value of '?'.\n",
    "data['ca'].value_counts()"
   ],
   "id": "656a0cbe191c5d0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For column 'thal', 2 records contains the value of '?'.\n",
    "data['thal'].value_counts()"
   ],
   "id": "44d78aae31062295",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's investigate if the total 6 (4 from 'ca' and 2 from 'thal') records are disjoint, using OR operator first.\n",
    "# Only when OR operator doesn't satisfy, we will use AND operator to further investigate if records are distributed between two features.\n",
    "# Looks like the sum is 6, and they are disjoint (using OR operator).\n",
    "data[(data['thal']=='?') | (data['ca']=='?')]"
   ],
   "id": "cd2ed89dba9f5e35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# There is only < 2% uninterpretable data found in 'ca' and 'thal' with '?' character.\n",
    "print(f'In ca there is {round(helper.value_count(data,'ca','?'),2)}% of ? values found.')\n",
    "print(f'In thal there is {round(helper.value_count(data,'thal','?'),2)}% of ? values found.')"
   ],
   "id": "f923a0bef9d81f6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observation:\n",
    "From the investigation, it appears feature `ca` and `thal` have uninterpretable values which is `?`. \\\n",
    "Together there are 6 records (4 from `ca` and 2 from `thal`) and they are disjoint. \\\n",
    "There is only less than 2% of uninterpretable data found in both `ca` and `thal`.\n",
    "\n",
    "### Conclusion\n",
    "Since features in the dataset were already narrowed from 76 to 14 based on their importance for meaningful medical interpretation, dropping the 6 records appears to be more reasonable. This reason: the two variables cannot be imputed with 'mean' because through they appears in numeric format they were originally in categorical format and were already converted.\n",
    "\n",
    "### Action(s)\n",
    "1. Drop records for feature `ca` and `thal` that are `?`"
   ],
   "id": "50a5566f8093fbf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop records for feature `ca` and `thal` that are `?` The new total records are 303 - 6 = 297.\n",
    "filtered = data[(data['thal'] == '?') | (data['ca'] == '?')].index\n",
    "data.drop(filtered, inplace=True)\n",
    "data.shape"
   ],
   "id": "52fa0f5d0189f5da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Does the dataset have empty columns (features)?\n",
    "Now that we have verified the data consistencies, let's <u>investigate if any data is missing in the dataset</u>."
   ],
   "id": "eddf09a4e6f44e1f"
  },
  {
   "cell_type": "code",
   "id": "2c98fef25a77d2a6",
   "metadata": {},
   "source": [
    "# No missing data. isnull and isna is the same, checking for None, NaN or NaT (datetime)\n",
    "data.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Is the dataset sufficient for building the model(s)?\n",
    "Now that the dataset was cleansed, let's explore the data for further analysis (with graphs when needed)."
   ],
   "id": "9a4a250b4589c58b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's save a copy of the cleansed dataset for building models.\n",
    "data.to_csv('data/uci-heart-disease/processed.cleveland-cleansed.data', index=False)\n",
    "\n",
    "# Load the saved data for verification.\n",
    "df = pd.read_csv('data/uci-heart-disease/processed.cleveland-cleansed.data')\n",
    "df"
   ],
   "id": "c2f753c2f69246a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e409564811cc21b",
   "metadata": {},
   "source": [
    "# Ideally we should expect both classes in the target variable to have same proportion, i.e. ~148.\n",
    "len(df[\"target\"]) / 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Nevertheless, a slight risk variation can be accepted. Let's investigate if the target class in balanced.\n",
    "df['target'].value_counts()"
   ],
   "id": "f915faf0978610a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# To get the percentage proportion, let's view the normalized value counts.\n",
    "# So, the deviation in the distribution is ~4%.\n",
    "df['target'].value_counts(normalize=True)"
   ],
   "id": "173ececa7ec57f12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see the distribution of target variable's class in bar-chart.\n",
    "df['target'].value_counts().plot(kind=\"bar\", color=['steelblue', 'darksalmon']);"
   ],
   "id": "d1548e43bf8030a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's investigate which features have strong correlation with target.\n",
    "df.corr()"
   ],
   "id": "536ecfcd0cc14cac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see the correlation matrix with color intensity spectrum - the darker the blue is, the higher the correlation.\n",
    "corr_matrix = df.corr(method='pearson')\n",
    "mask = np.triu(np.ones_like(data.corr()))\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.heatmap(corr_matrix,\n",
    "            mask=mask,\n",
    "            annot=True,\n",
    "            linewidths=0.5,\n",
    "            fmt= \".2f\",\n",
    "            cmap=\"GnBu\");"
   ],
   "id": "a5cc70a160114c7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.1 Feature Correlation\n",
    "By eyeballing the chart (above), we can conclude the following from the Pearson's correlation.\n",
    "\n",
    "| Level     |   Positive   |    Negative    |\n",
    "|:----------|:------------:|:--------------:|\n",
    "| Strong    |  0.70 to 1   |  -0.70 to -1   |\n",
    "| Moderate  | 0.30 to 0.70 | -0.30 to -0.70 |\n",
    "| Weak      |  0 to 0.30   |   0 to -0.30   |\n",
    "\n",
    "If we apply the <u>general rules for classifying correlation</u> (using the table above), we observe:\n",
    "* Features have <u>only moderate correlation</u> between each other and target variable.\n",
    "#### Positive correlation - positive linear relationship\n",
    "* Six features has moderate <u>postive correlation to target</u> variable:\n",
    "1. thal (0.53)\n",
    "2. ca (0.46)\n",
    "3. oldpeak (0.42)\n",
    "4. exang (0.42)\n",
    "5. cp (0.41)\n",
    "6. slope (0.33)\n",
    "* Six features has moderate <u>positive correlation between variables</u>:\n",
    "1. oldpeak and slope (0.58)\n",
    "2. sex and thal (0.38)\n",
    "3. cp and exang (0.38)\n",
    "4. age and ca (0.36)\n",
    "5. oldpeak and thal (0.34)\n",
    "6. exang and thal (0.33)\n",
    "#### Negative correlation - negative (inverse) linear relationship\n",
    "* One feature has moderate <u>negative correlation to target</u> variable:\n",
    "1. thalach (-0.42)\n",
    "* Six features has moderate <u> negative correlation between variables</u>:\n",
    "1. age and thalach (-0.39)\n",
    "2. thalach and slope (-0.39)\n",
    "3. thalach and exang (-0.38)\n",
    "4. thalach and oldpeak (-0.35)\n",
    "2. cp and thalach (-0.34)\n",
    "3. thalach and thal (-0.27)\n",
    "4. thalach and ca (-0.27)\n",
    "\n",
    "### Further investigation needed\n",
    "We applied pearson's correlation to identify the correlation. We also need to investigate the following to ensure :\n",
    "- both variables are quantitative\n",
    "- variables are normally distributed\n",
    "- no outliers\n",
    "* Let's find the top 3 variables and investigate:\n",
    "1. oldpeak and slope (0.58)\n",
    "2. thal and target (0.53)\n",
    "3. ca and target (0.42)\n",
    "* And, one negative correlation:\n",
    "1. thalach and target (-0.42)"
   ],
   "id": "7d29b468ba3d158d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The curve is slightly right skewed. Mean and median also be slightly on the right.\n",
    "reload(helper)\n",
    "helper.draw_histogram_density_curve(df,'trestbps')"
   ],
   "id": "5a02ea0755ca8d27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['trestbps'].describe()",
   "id": "7cf4ff70e9941401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Q3 = df['trestbps'].quantile(0.75)",
   "id": "acb800f470ffdffc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8d5fd5ab34faec72",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
