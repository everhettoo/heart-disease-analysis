{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Objective\n",
    "We found out from [processed-dataset-investigation](2.1-uci-processed-dataset-investigation.ipynb) that 99% data from processed files (supplied by UCI database) has missing values in the following datasets:\n",
    "- Long Beach (VA) `processed.va.data`\n",
    "- Hungarian `processed.hungarian.data`\n",
    "- Switzerland `processed.switzerland.data`\n",
    "\n",
    "These were the processed datasets made available by UCI.\n",
    "\n",
    "Since the provided processed datasets are useless, we are going to investigate the raw files here in an attempt to recover data from it.\n",
    "\n"
   ],
   "id": "1febac6dc36863f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# After the original dataset was downloaded, few files are extracted in the `/heart-disease` directory. To investigate the contents of the dataset, the `cat` cmd can be used on `Index` file.\n",
    "!cat data/uci-heart-disease/Index"
   ],
   "id": "5cc4224ae5ccd9df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For unknown reasons, the `cleveland.data` got corrupted during upload and became beyond recoverable. This was mentioned in the `WARNING` file.\n",
    "!cat data/uci-heart-disease/WARNING"
   ],
   "id": "35339eb22980b95c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Though other raw data files (hungarian.data, long-beach-va.data and switzerland.data) are in `ascii` format, the `cleveland.data` file found to be in binary format and indicates uploading disruption. This can be investigated with `file -I` cmd.\n",
    "# Originally, 'text/plain' protocol was used to upload (transfer) with charset=us-ascii for encoding.\n",
    "!file -I data/uci-heart-disease/hungarian.data"
   ],
   "id": "9ef4e3e665e2c4ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Meanwhile, for the corrupted 'cleveland.data file, 'octet-stream' protocol was used to upload (transfer) with charset=binary for encoding.\n",
    "!file -I data/uci-heart-disease/cleveland.data"
   ],
   "id": "2e54b800061afe06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Though the first half of `cleveland.data` file seem in `ascii` format, when `tail -n 100 cleveland.data` was used, the second half of the file appears in binary encoding. This can be observed with gibberish characters.\n",
    "!tail -n 100 data/uci-heart-disease/cleveland.data"
   ],
   "id": "3b9ce9f3acf9a9c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Assuming only the processed datasets had missing values, an attempt to recover data from raw dataset was made in [process-raw-files](1.2-preprocess_raw_dataset.py) as described in table below:\n",
    "\n",
    "| Dataset Name | Raw filename       | Recovered filename         |\n",
    "|:------------:|:-------------------|:---------------------------|\n",
    "|  Long Beach  | long-beach-va.data | recovered-va.data          |\n",
    "|  Hungarian   | hungarian.data     | recovered-hungarian.data   |\n",
    "| Switzerland  | switzerland.data   | recovered-switzerland.data |\n",
    "\n",
    "In this notebook we are going to investigate if we can recover data from the `recovered` files."
   ],
   "id": "cbca5221698a819d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "36795f57afcc4c94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# All required libraries.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt;\n",
    "import seaborn as sns;\n",
    "from custom_libs import helper\n",
    "from importlib import reload\n",
    "import numpy as np"
   ],
   "id": "9777575d384fd7b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Long Beach (VA)",
   "id": "66c0ac3b6916bb60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The recovered dataset has 76 original columns.\n",
    "raw_data = pd.read_csv('data/uci-heart-disease/recovered-va.data')\n",
    "raw_data.head(5)"
   ],
   "id": "d1df3fc095782671",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "header =['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "data = raw_data[header]\n",
    "# 303 records and 14 columns.\n",
    "data.head(5)"
   ],
   "id": "64169d724cdd2474",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 200 records found.\n",
    "data.shape"
   ],
   "id": "2a97255520d4be0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# In the uci-processed-dataset-investigation notebook we saw the following features was missing.\n",
    "# object: ['trestbps', 'chol', 'fbs', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
    "# In the processed file the missing value was marked as '?', while in the raw file it was marked as -9.\n",
    "invalid_data = data[(data['trestbps']==-9)\n",
    "      |(data['chol']==-9)\n",
    "      |(data['fbs']==-9)\n",
    "      |(data['thalach']==-9)\n",
    "      |(data['exang']==-9)\n",
    "      |(data['oldpeak']==-9)\n",
    "      |(data['slope']==-9)\n",
    "      |(data['ca']==-9)\n",
    "      |(data['thal']==-9)\n",
    " ]\n",
    "\n",
    "# Records with invalid data => 200 - 199 = 1 (Balance one that can be salvaged)\n",
    "invalid_data.shape"
   ],
   "id": "5b6b5242d0fc4f4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dropping the invalid data and salvaging the valid one(s).\n",
    "data.drop(invalid_data.index, inplace=True)\n",
    "valid_data = data\n",
    "valid_data"
   ],
   "id": "904a03301a537f21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hungarian",
   "id": "e31ceea70acddaa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The recovered dataset has 76 original columns.\n",
    "raw_data = pd.read_csv('data/uci-heart-disease/recovered-hungarian.data')\n",
    "raw_data.head(5)"
   ],
   "id": "a658645413a405db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "header =['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "data = raw_data[header]\n",
    "# 303 records and 14 columns.\n",
    "data.head(5)"
   ],
   "id": "4cc11fad5bac521e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 294 records found.\n",
    "data.shape"
   ],
   "id": "e41d876eeccc7601",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# In the uci-processed-dataset-investigation notebook we saw the following features was missing.\n",
    "# object: ['trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'slope', 'ca', 'thal']}\n",
    "# In the processed file the missing value was marked as '?', while in the raw file it was marked as -9.\n",
    "invalid_data = data[(data['trestbps']==-9)\n",
    "      |(data['chol']==-9)\n",
    "      |(data['fbs']==-9)\n",
    "      |(data['restecg']==-9)\n",
    "      |(data['thalach']==-9)\n",
    "      |(data['exang']==-9)\n",
    "      |(data['slope']==-9)\n",
    "      |(data['ca']==-9)\n",
    "      |(data['thal']==-9)\n",
    " ]\n",
    "\n",
    "# Records with invalid data => 294 - 293 = 1 (Balance one that can be salvaged)\n",
    "invalid_data.shape"
   ],
   "id": "ee8a18df568008b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # Dropping the invalid data and salvaging the valid one(s).\n",
    "data.drop(invalid_data.index, inplace=True)\n",
    "tmp = data\n",
    "tmp"
   ],
   "id": "30c4328e610f9b39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "valid_data = pd.concat([valid_data, tmp], ignore_index=True)\n",
    "# valid_data.reset_index(drop=True, inplace=True)\n",
    "valid_data"
   ],
   "id": "7be6599d9d91e786",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Switzerland",
   "id": "f81db35eca1e84b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The recovered dataset has 76 original columns.\n",
    "raw_data = pd.read_csv('data/uci-heart-disease/recovered-switzerland.data')\n",
    "raw_data.head(5)"
   ],
   "id": "47e954e5db4b96a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "header =['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "data = raw_data[header]\n",
    "# 303 records and 14 columns.\n",
    "data.head(5)"
   ],
   "id": "bb609bda91203ec6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 123 records found.\n",
    "data.shape"
   ],
   "id": "4a3c8b7e984e74eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# In the uci-processed-dataset-investigation notebook we saw the following features was missing.\n",
    "# object: ['trestbps', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']}\n",
    "# In the processed file the missing value was marked as '?', while in the raw file it was marked as -9.\n",
    "invalid_data = data[(data['trestbps']==-9)\n",
    "      |(data['fbs']==-9)\n",
    "      |(data['restecg']==-9)\n",
    "      |(data['thalach']==-9)\n",
    "      |(data['exang']==-9)\n",
    "      |(data['oldpeak']==-9)\n",
    "      |(data['slope']==-9)\n",
    "      |(data['ca']==-9)\n",
    "      |(data['thal']==-9)\n",
    " ]\n",
    "\n",
    "# Records with invalid data => 123 - 123 = 0 (Nothing to salvage)\n",
    "invalid_data.shape"
   ],
   "id": "129df621cbae775a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
