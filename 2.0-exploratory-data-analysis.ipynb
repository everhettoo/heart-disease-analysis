{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Objective\n",
    "In attempts to build ML models using the UCI Heart-Disease dataset, the following questions will be clarified in this stage (data exploration).\n",
    "1. What problem needs solving?\n",
    "2. What data the dataset contains?\n",
    "3. Which feature appears more important than the other?\n",
    "4. What is the outcome expectation?\n",
    "\n",
    "Once, these questions are clarified, a list of action items can help for next stage."
   ],
   "id": "f0eb4ade433a0269"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load required libraries.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt;\n",
    "import seaborn as sns;\n",
    "from custom_libs import helper\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import models.uci_heart_disease_dataset as uci\n",
    "from models.uci_heart_disease_dataset import UCIHeartDiseaseData"
   ],
   "id": "8f21e87a43621955",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "890749f0a123e02b",
   "metadata": {},
   "source": [
    "reload(uci)\n",
    "# There is no header in the processed data file. Therefore, following original names can be mapped.\n",
    "# header =['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "# The library 'uci_heart_disease_dataset' was created to handle UCI dataset related matters.\n",
    "# So, the 'get_standard_features' method returns a meaningful name instead for fluidity.\n",
    "data = pd.read_csv(uci.UCIHeartDiseaseDataFile.cleveland_standard, names=uci.get_standard_features())\n",
    "\n",
    "# 303 records and 14 columns.\n",
    "data.head(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. What problem needs solving?\n",
    "<b>Classify</b> - whether a patient has heart disease based on his/her medical data.\n",
    "\n",
    "At a glance, it appears to be binary classification problem.\\\n",
    "From the data-dictionary, `Target` appears as the target variable. Let's investigate the target variable's supportability for <u>binary classification</u> problem."
   ],
   "id": "322ef85552d321e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Target variable has integer data-type.\n",
    "data.info()"
   ],
   "id": "cc0d8512f6a6ebce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Target variable has more than two values/classes. Meanwhile, binary classification requires only 2 values/classes.\n",
    "data[uci.UCIHeartDiseaseData.target].value_counts()"
   ],
   "id": "e25a1afb0b274595",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observation:\n",
    "The target variable cannot support binary classification since it has more than 2 values/classes.\n",
    "\n",
    "If we understood the original intention from the [data-dictionary](data_dictionary) and the literature:\n",
    "- Any patient with less than 50% vessel narrowing was marked as `value: 0` -- no heart disease\n",
    "- Any patient with more than 50% vessel narrowing was marked as `value: 1` -- has heart disease. This was further expanded to 1, 2, 3 and 4 based on affected major vessel.\n",
    "\n",
    "### Conclusion:\n",
    "We can safely convert this to a binary classification problem by replacing any values of target variable other than `0` to `1`. This logically simplifies that any patient with vessel narrowing more than 50% is suspected to have heart-disease (without distorting the original meaning much)."
   ],
   "id": "20a1761f4ac8c562"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert any values in target variable other than `0` to `1` - to support binary classification problem.\n",
    "# The sum of 1, 2, 3 and 4 should total up to 55 + 36 + 35 + 13 = 139.\n",
    "data.loc[data[uci.UCIHeartDiseaseData.target]!=0,uci.UCIHeartDiseaseData.target]=1\n",
    "data[uci.UCIHeartDiseaseData.target].value_counts()"
   ],
   "id": "cd010bc96be740b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Does the dataset have duplicate rows (records)?\n",
    "So, we converted the target variable from multi-class to binary to support binary classification problem. \\\n",
    "Now, let's investigate if any duplicate records (rows) present in the dataset."
   ],
   "id": "525c3df77669b28e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# All columns were checked, and no duplicate record found.\n",
    "data[data.duplicated()]"
   ],
   "id": "d430b6044ff55447",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. What data-types the dataset contains?\n",
    "We got the basic idea about the data types from the 'data-dictionary'. let's investigate and verify further the content."
   ],
   "id": "14e49292b4c2276e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# There are 11 numerical (float and int) data and two objects ('Major Vessels' and 'Thalasemia')\n",
    "# The dictionary indicated all processed data is in numerical format. Let's investigate.\n",
    "data.info()"
   ],
   "id": "24c19fe43fa345cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's check for missing data (isnull/isna checks for None, NaN or NaT (datetime)) - should be sufficient for detecting missing values.\n",
    "# Result shows no missing values. But why the data types for 'Major Vessels' and 'Thalassemia' are not numeric as indicated by data-dictionary?\n",
    "# Let's investigate further manually - in the next cell.\n",
    "data.isnull().sum()"
   ],
   "id": "b982da583552187b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 'Major Vessels' and 'Thalassemia' should be numerical. However, it is marked as '?'. Someone marked 6 entries with missing value '?', supposedly.\n",
    "for item in uci.get_standard_features():\n",
    "    d = data[item]\n",
    "    if d.dtype == 'object':\n",
    "        print(data[item].value_counts())"
   ],
   "id": "656a0cbe191c5d0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For column 'Thalassemia', 2 records contains the value of '?'.\n",
    "data[uci.UCIHeartDiseaseData.thalassemia].value_counts()"
   ],
   "id": "44d78aae31062295",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Looks like the sum is 6, and they are disjointed (4 from 'Major Vessels' and 2 from 'Thalassemia'):\n",
    "data[(data[uci.UCIHeartDiseaseData.thalassemia]=='?') | (data[uci.UCIHeartDiseaseData.major_vessels]=='?')]"
   ],
   "id": "cd2ed89dba9f5e35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:33:48.547881Z",
     "start_time": "2024-12-23T09:33:48.544919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# There is only < 2% missing values for  'Major Vessels' and 'Thalassemia' with '?'\n",
    "print(f'In ca there is {round(helper.value_count(data,uci.UCIHeartDiseaseData.major_vessels,'?'),2)}% of ? values found.')\n",
    "print(f'In thal there is {round(helper.value_count(data,UCIHeartDiseaseData.thalassemia,'?'),2)}% of ? values found.')"
   ],
   "id": "f923a0bef9d81f6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ca there is 1.32% of ? values found.\n",
      "In thal there is 0.66% of ? values found.\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observation:\n",
    "- From the investigation, it appears feature `Major Vessels` and `Thalassemia` have missing values marked as `?`. \\\n",
    "- Together there are 6 records (4 from `Major Vessels` and 2 from `Thalassemia`) and they are disjoint. \\\n",
    "- There is only less than 2% of uninterpretable data found in both `Major Vessels` and `Thalassemia`.\n",
    "\n",
    "### Conclusion\n",
    "- Though there are only 6 records with undocumented missing value '?', how about the other datasets (Long Beach, Hungarian and Switzerland)?\n",
    "- Let's investigate the other datasets before proceeding"
   ],
   "id": "50a5566f8093fbf6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A Brief Investigation on Other Datasets",
   "id": "8263e3389569c180"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:48:56.149617Z",
     "start_time": "2024-12-23T09:48:56.142929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(uci)\n",
    "data = pd.read_csv(uci.UCIHeartDiseaseDataFile.hungarian_standard, names=uci.get_standard_features())\n",
    "for item in uci.get_standard_features():\n",
    "    d = data[item]\n",
    "    if d.dtype == 'object':\n",
    "        print(f'In ca there is {round(helper.value_count(data,item,'?'),2)}% of ? values found.')"
   ],
   "id": "826514199d29c1dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ca there is 0.34% of ? values found.\n",
      "In ca there is 7.82% of ? values found.\n",
      "In ca there is 2.72% of ? values found.\n",
      "In ca there is 0.34% of ? values found.\n",
      "In ca there is 0.34% of ? values found.\n",
      "In ca there is 0.34% of ? values found.\n",
      "In ca there is 64.63% of ? values found.\n",
      "In ca there is 98.98% of ? values found.\n",
      "In ca there is 90.48% of ? values found.\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:49:44.042853Z",
     "start_time": "2024-12-23T09:49:44.036424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(uci)\n",
    "data = pd.read_csv(uci.UCIHeartDiseaseDataFile.longbeach_standard, names=uci.get_standard_features())\n",
    "for item in uci.get_standard_features():\n",
    "    d = data[item]\n",
    "    if d.dtype == 'object':\n",
    "        print(f'In ca there is {round(helper.value_count(data,item,'?'),2)}% of ? values found.')"
   ],
   "id": "55438b8cf1cbf196",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ca there is 28.0% of ? values found.\n",
      "In ca there is 3.5% of ? values found.\n",
      "In ca there is 3.5% of ? values found.\n",
      "In ca there is 26.5% of ? values found.\n",
      "In ca there is 26.5% of ? values found.\n",
      "In ca there is 28.0% of ? values found.\n",
      "In ca there is 51.0% of ? values found.\n",
      "In ca there is 99.0% of ? values found.\n",
      "In ca there is 83.0% of ? values found.\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:51:35.596117Z",
     "start_time": "2024-12-23T09:51:35.589758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(uci)\n",
    "data = pd.read_csv(uci.UCIHeartDiseaseDataFile.switzerland_standard, names=uci.get_standard_features())\n",
    "for item in uci.get_standard_features():\n",
    "    d = data[item]\n",
    "    if d.dtype == 'object':\n",
    "        print(f'[{item}] has {round(helper.value_count(data,item,'?'),2)}% of ? values.')"
   ],
   "id": "96d7b815107a2ff6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BP Systolic] has 1.63% of ? values.\n",
      "[Blood Sugar] has 60.98% of ? values.\n",
      "[Rest ECG] has 0.81% of ? values.\n",
      "[Exe. Max Heartrate] has 0.81% of ? values.\n",
      "[Exe. induced Angina] has 0.81% of ? values.\n",
      "[Exe. ST Depression] has 4.88% of ? values.\n",
      "[Exe. ST Segment Slope] has 13.82% of ? values.\n",
      "[Major Vessels] has 95.93% of ? values.\n",
      "[Thalassemia] has 42.28% of ? values.\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Since features in the dataset were already narrowed from 76 to 14 based on their importance for meaningful medical interpretation, dropping the 6 records appears to be more reasonable. This reason: the two variables cannot be imputed with 'mean' because through they appears in numeric format they were originally in categorical format and were already converted.\n",
    "\n",
    "\n",
    "### Important Notice\n",
    "- Other datasets (Long Beach, Hungarian and Switzerland) also contains the `?` character in many of its features rendering the datasets useless. Please refer to [data set investigation](1.1-uci-processed-dataset-investigation.ipynb) for more reports."
   ],
   "id": "598b7879472d5754"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop records for feature `ca` and `thal` that are `?` The new total records are 303 - 6 = 297.\n",
    "filtered = data[(data['thal'] == '?') | (data['ca'] == '?')].index\n",
    "data.drop(filtered, inplace=True)\n",
    "data.shape"
   ],
   "id": "52fa0f5d0189f5da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Does the dataset have empty columns (features)?\n",
    "Now that we have verified the data consistencies, let's <u>investigate if any data is missing in the dataset</u>."
   ],
   "id": "eddf09a4e6f44e1f"
  },
  {
   "cell_type": "code",
   "id": "2c98fef25a77d2a6",
   "metadata": {},
   "source": [
    "# No missing data. isnull and isna is the same, checking for None, NaN or NaT (datetime)\n",
    "data.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Is the dataset sufficient for building the model(s)?\n",
    "Now that the dataset was cleansed, let's explore the data for further analysis (with graphs when needed)."
   ],
   "id": "9a4a250b4589c58b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's save a copy of the cleansed dataset for building models.\n",
    "data.to_csv('data/uci-heart-disease/processed.cleveland-cleansed.data', index=False)\n",
    "\n",
    "# Load the saved data for verification.\n",
    "df = pd.read_csv('data/uci-heart-disease/processed.cleveland-cleansed.data')\n",
    "df"
   ],
   "id": "c2f753c2f69246a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e409564811cc21b",
   "metadata": {},
   "source": [
    "# Ideally we should expect both classes in the target variable to have same proportion, i.e. ~148.\n",
    "len(df[\"target\"]) / 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Nevertheless, a slight risk variation can be accepted. Let's investigate if the target class in balanced.\n",
    "df['target'].value_counts()"
   ],
   "id": "f915faf0978610a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# To get the percentage proportion, let's view the normalized value counts.\n",
    "# So, the deviation in the distribution is ~4%.\n",
    "df['target'].value_counts(normalize=True)"
   ],
   "id": "173ececa7ec57f12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see the distribution of target variable's class in bar-chart.\n",
    "df['target'].value_counts().plot(kind=\"bar\", color=['steelblue', 'darksalmon']);"
   ],
   "id": "d1548e43bf8030a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's investigate which features have strong correlation with target.\n",
    "df.corr()"
   ],
   "id": "536ecfcd0cc14cac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see the correlation matrix with color intensity spectrum - the darker the blue is, the higher the correlation.\n",
    "corr_matrix = df.corr(method='pearson')\n",
    "mask = np.triu(np.ones_like(data.corr()))\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.heatmap(corr_matrix,\n",
    "            mask=mask,\n",
    "            annot=True,\n",
    "            linewidths=0.5,\n",
    "            fmt= \".2f\",\n",
    "            cmap=\"GnBu\");"
   ],
   "id": "a5cc70a160114c7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.1 Feature Correlation\n",
    "By eyeballing the chart (above), we can conclude the following from the Pearson's correlation.\n",
    "\n",
    "| Level     |   Positive   |    Negative    |\n",
    "|:----------|:------------:|:--------------:|\n",
    "| Strong    |  0.70 to 1   |  -0.70 to -1   |\n",
    "| Moderate  | 0.30 to 0.70 | -0.30 to -0.70 |\n",
    "| Weak      |  0 to 0.30   |   0 to -0.30   |\n",
    "\n",
    "If we apply the <u>general rules for classifying correlation</u> (using the table above), we observe:\n",
    "* Features have <u>only moderate correlation</u> between each other and target variable.\n",
    "#### Positive correlation - positive linear relationship\n",
    "* Six features has moderate <u>postive correlation to target</u> variable:\n",
    "1. thal (0.53)\n",
    "2. ca (0.46)\n",
    "3. oldpeak (0.42)\n",
    "4. exang (0.42)\n",
    "5. cp (0.41)\n",
    "6. slope (0.33)\n",
    "* Six features has moderate <u>positive correlation between variables</u>:\n",
    "1. oldpeak and slope (0.58)\n",
    "2. sex and thal (0.38)\n",
    "3. cp and exang (0.38)\n",
    "4. age and ca (0.36)\n",
    "5. oldpeak and thal (0.34)\n",
    "6. exang and thal (0.33)\n",
    "#### Negative correlation - negative (inverse) linear relationship\n",
    "* One feature has moderate <u>negative correlation to target</u> variable:\n",
    "1. thalach (-0.42)\n",
    "* Six features has moderate <u> negative correlation between variables</u>:\n",
    "1. age and thalach (-0.39)\n",
    "2. thalach and slope (-0.39)\n",
    "3. thalach and exang (-0.38)\n",
    "4. thalach and oldpeak (-0.35)\n",
    "2. cp and thalach (-0.34)\n",
    "3. thalach and thal (-0.27)\n",
    "4. thalach and ca (-0.27)\n",
    "\n",
    "### Further investigation needed\n",
    "We applied pearson's correlation to identify the correlation. We also need to investigate the following to ensure :\n",
    "- both variables are quantitative\n",
    "- variables are normally distributed\n",
    "- no outliers\n",
    "* Let's find the top 3 variables and investigate:\n",
    "1. oldpeak and slope (0.58)\n",
    "2. thal and target (0.53)\n",
    "3. ca and target (0.42)\n",
    "* And, one negative correlation:\n",
    "1. thalach and target (-0.42)"
   ],
   "id": "7d29b468ba3d158d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The curve is slightly right skewed. Mean and median also be slightly on the right.\n",
    "reload(helper)\n",
    "helper.draw_histogram_density_curve(df,'trestbps')"
   ],
   "id": "5a02ea0755ca8d27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['trestbps'].describe()",
   "id": "7cf4ff70e9941401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Q3 = df['trestbps'].quantile(0.75)",
   "id": "acb800f470ffdffc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8d5fd5ab34faec72",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
