{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The Objective\n",
    "In attempts to build ML models using the heart-disease dataset, the following questions needs clarification in this stage (data exploration).\n",
    "1. What problem needs to be solved?\n",
    "2. Does the dataset have duplicate rows (records)?\n",
    "3. What data-types the dataset contains?\n",
    "4. Does the dataset have empty columns (features)?\n",
    "5. Is the dataset sufficient for building the model(s)?\n",
    "6. Which feature appears more important than the other?\n",
    "\n",
    "Once, these questions are clarified, a list of action items can help for next stage."
   ],
   "id": "f0eb4ade433a0269"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's load the necessary libraries and data for investigation.",
   "id": "9a9a9d5e14e695d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:07:47.928463Z",
     "start_time": "2024-12-19T09:07:47.926151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# All required libraries.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt;\n",
    "import seaborn as sns;\n",
    "from custom_libs import helper\n",
    "from importlib import reload\n",
    "import numpy as np"
   ],
   "id": "8f21e87a43621955",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "890749f0a123e02b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:07:49.902772Z",
     "start_time": "2024-12-19T09:07:49.886093Z"
    }
   },
   "source": [
    "header =['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "data = pd.read_csv('data/uci-heart-disease/processed.cleveland.data', names=header)\n",
    "# 303 records and 14 columns.\n",
    "data.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  num  \n",
       "0    3.0  0.0  6.0    0  \n",
       "1    2.0  3.0  3.0    2  \n",
       "2    2.0  2.0  7.0    1  \n",
       "3    3.0  0.0  3.0    0  \n",
       "4    1.0  0.0  3.0    0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. What problem needs to be solved?\n",
    "<b>Classify</b> - whether a patient has heart disease based on his/her medical data.\n",
    "\n",
    "At a glance, it appears to be binary classification problem.\\\n",
    "From the data-dictionary, `num` appears as the target variable. Let's investigate the target variable's supportability for <u>binary classification</u> problem."
   ],
   "id": "322ef85552d321e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:07:52.125881Z",
     "start_time": "2024-12-19T09:07:52.120656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Target variable (num) has integer data-type.\n",
    "data.info()"
   ],
   "id": "cc0d8512f6a6ebce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    float64\n",
      " 1   sex       303 non-null    float64\n",
      " 2   cp        303 non-null    float64\n",
      " 3   trestbps  303 non-null    float64\n",
      " 4   chol      303 non-null    float64\n",
      " 5   fbs       303 non-null    float64\n",
      " 6   restecg   303 non-null    float64\n",
      " 7   thalach   303 non-null    float64\n",
      " 8   exang     303 non-null    float64\n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    float64\n",
      " 11  ca        303 non-null    object \n",
      " 12  thal      303 non-null    object \n",
      " 13  num       303 non-null    int64  \n",
      "dtypes: float64(11), int64(1), object(2)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:07:54.143026Z",
     "start_time": "2024-12-19T09:07:54.139002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Target variable (num) has more than two values/classes. Meanwhile, binary classification requires only 2 values/classes.\n",
    "data['num'].value_counts()"
   ],
   "id": "e25a1afb0b274595",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    164\n",
       "1     55\n",
       "2     36\n",
       "3     35\n",
       "4     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observation:\n",
    "The target variable (num) cannot support binary classification since it has more than 2 values/classes. \\\n",
    "If we understood the original intention from the data-dictionary and the literature:\n",
    "- Any patient with less than 50% vessel narrowing was marked as `value: 0` -- no heart disease\n",
    "- Any patient with more than 50% vessel narrowing was marked as `value: 1` -- has heart disease. This was further expanded to 1, 2, 3 and 4 based on affected major vessel.\n",
    "\n",
    "### Conclusion:\n",
    "We <u>can safely convert this to a binary classification problem</u> by replacing any values of target variable (num) other than `0` to `1`. This logically simplifies that any patient with vessel narrowing more than 50% is suspected to have heart-disease (without distorting the original meaning much).\n",
    "\n",
    "### Action(s)\n",
    "1. Convert any values in target variable (num) other than `0` to `1` - to support binary classification problem.\n",
    "2. Also, rename the target variable from `num` to `target` to give a more meaningful name."
   ],
   "id": "20a1761f4ac8c562"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:07:57.375284Z",
     "start_time": "2024-12-19T09:07:57.371078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Convert any values in target variable (num) other than `0` to `1` - to support binary classification problem.\n",
    "# Let's see the count before conversion\n",
    "data['num'].value_counts()"
   ],
   "id": "cd010bc96be740b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    164\n",
       "1     55\n",
       "2     36\n",
       "3     35\n",
       "4     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:07:59.711697Z",
     "start_time": "2024-12-19T09:07:59.707412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's see if the sum of 1, 2, 3 and 4 has total up to 55 + 36 + 35 + 13 = 139.\n",
    "data.loc[data['num']!=0,\"num\"]=1\n",
    "data['num'].value_counts()"
   ],
   "id": "4d29b68f7f6e02cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    164\n",
       "1    139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:08:02.617699Z",
     "start_time": "2024-12-19T09:08:02.614873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Also, rename the target variable from `num` to `target` to give a more meaningful name.\n",
    "data.rename(columns={'num':'target'}, inplace=True)"
   ],
   "id": "d75fd6df4eb67d3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:08:03.753603Z",
     "start_time": "2024-12-19T09:08:03.750046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The new 'target' column tallies with the old 'num' column.\n",
    "data['target'].value_counts()"
   ],
   "id": "3b6b718bc8b4bf6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    164\n",
       "1    139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Does the dataset have duplicate rows (records)?\n",
    "So, we converted the target variable from multi-class to binary to support binary classification problem. \\\n",
    "Now, let's investigate if any duplicate records (rows) present in the dataset."
   ],
   "id": "525c3df77669b28e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:08:08.410583Z",
     "start_time": "2024-12-19T09:08:08.405044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# All columns were checked, and no duplicate record found.\n",
    "data[data.duplicated()]"
   ],
   "id": "d430b6044ff55447",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. What data-types the dataset contains?\n",
    "We got the basic idea about the data types from the 'data-dictionary'. let's investigate and verify further the content."
   ],
   "id": "14e49292b4c2276e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:08:10.739066Z",
     "start_time": "2024-12-19T09:08:10.734614Z"
    }
   },
   "cell_type": "code",
   "source": "data.info()",
   "id": "24c19fe43fa345cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    float64\n",
      " 1   sex       303 non-null    float64\n",
      " 2   cp        303 non-null    float64\n",
      " 3   trestbps  303 non-null    float64\n",
      " 4   chol      303 non-null    float64\n",
      " 5   fbs       303 non-null    float64\n",
      " 6   restecg   303 non-null    float64\n",
      " 7   thalach   303 non-null    float64\n",
      " 8   exang     303 non-null    float64\n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    float64\n",
      " 11  ca        303 non-null    object \n",
      " 12  thal      303 non-null    object \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(11), int64(1), object(2)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All features appears to be in numerical format except for `ca` and `thal`. They appear to be categorical from 'data-dictionary'. Let's investigate further.",
   "id": "f32bc124eb443b99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:08:13.191960Z",
     "start_time": "2024-12-19T09:08:13.187659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For column 'ca', 4 records contains the value of '?'.\n",
    "data['ca'].value_counts()"
   ],
   "id": "656a0cbe191c5d0c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca\n",
       "0.0    176\n",
       "1.0     65\n",
       "2.0     38\n",
       "3.0     20\n",
       "?        4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:08:17.256624Z",
     "start_time": "2024-12-19T09:08:17.252683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For column 'thal', 2 records contains the value of '?'.\n",
    "data['thal'].value_counts()"
   ],
   "id": "44d78aae31062295",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thal\n",
       "3.0    166\n",
       "7.0    117\n",
       "6.0     18\n",
       "?        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:08:18.020955Z",
     "start_time": "2024-12-19T09:08:18.011589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's investigate if the total 6 (4 from 'ca' and 2 from 'thal') records are disjoint, using OR operator first.\n",
    "# Only when OR operator doesn't satisfy, we will use AND operator to further investigate if records are distributed between two features.\n",
    "# Looks like the sum is 6, and they are disjoint (using OR operator).\n",
    "data[(data['thal']=='?') | (data['ca']=='?')]"
   ],
   "id": "cd2ed89dba9f5e35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "87   53.0  0.0  3.0     128.0  216.0  0.0      2.0    115.0    0.0      0.0   \n",
       "166  52.0  1.0  3.0     138.0  223.0  0.0      0.0    169.0    0.0      0.0   \n",
       "192  43.0  1.0  4.0     132.0  247.0  1.0      2.0    143.0    1.0      0.1   \n",
       "266  52.0  1.0  4.0     128.0  204.0  1.0      0.0    156.0    1.0      1.0   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  target  \n",
       "87     1.0  0.0    ?       0  \n",
       "166    1.0    ?  3.0       0  \n",
       "192    2.0    ?  7.0       1  \n",
       "266    2.0  0.0    ?       1  \n",
       "287    2.0    ?  7.0       0  \n",
       "302    1.0    ?  3.0       0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T09:08:23.366488Z",
     "start_time": "2024-12-19T09:08:23.363331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# There is only < 2% uninterpretable data found in 'ca' and 'thal' with '?' character.\n",
    "print(f'In ca there is {round(helper.value_count(data,'ca','?'),2)}% of ? values found.')\n",
    "print(f'In thal there is {round(helper.value_count(data,'thal','?'),2)}% of ? values found.')"
   ],
   "id": "f923a0bef9d81f6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ca there is 1.32% of ? values found.\n",
      "In thal there is 0.66% of ? values found.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observation:\n",
    "From the investigation, it appears feature `ca` and `thal` have uninterpretable values which is `?`. \\\n",
    "Together there are 6 records (4 from `ca` and 2 from `thal`) and they are disjoint. \\\n",
    "There is only less than 2% of uninterpretable data found in both `ca` and `thal`.\n",
    "\n",
    "### Conclusion\n",
    "Since features in the dataset were already narrowed from 76 to 14 based on their importance for meaningful medical interpretation, dropping the 6 records appears to be more reasonable. This reason: the two variables cannot be imputed with 'mean' because through they appears in numeric format they were originally in categorical format and were already converted.\n",
    "\n",
    "### Action(s)\n",
    "1. Drop records for feature `ca` and `thal` that are `?`\n",
    "\n",
    "### Important Notice\n",
    "- Other datasets (Long Beach, Hungarian and Switzerland) also contains the `?` character in many of its features rendering the datasets useless. Please refer to [data set investigation](1.1-uci-processed-dataset-investigation.ipynb) for more reports."
   ],
   "id": "50a5566f8093fbf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop records for feature `ca` and `thal` that are `?` The new total records are 303 - 6 = 297.\n",
    "filtered = data[(data['thal'] == '?') | (data['ca'] == '?')].index\n",
    "data.drop(filtered, inplace=True)\n",
    "data.shape"
   ],
   "id": "52fa0f5d0189f5da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Does the dataset have empty columns (features)?\n",
    "Now that we have verified the data consistencies, let's <u>investigate if any data is missing in the dataset</u>."
   ],
   "id": "eddf09a4e6f44e1f"
  },
  {
   "cell_type": "code",
   "id": "2c98fef25a77d2a6",
   "metadata": {},
   "source": [
    "# No missing data. isnull and isna is the same, checking for None, NaN or NaT (datetime)\n",
    "data.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Is the dataset sufficient for building the model(s)?\n",
    "Now that the dataset was cleansed, let's explore the data for further analysis (with graphs when needed)."
   ],
   "id": "9a4a250b4589c58b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's save a copy of the cleansed dataset for building models.\n",
    "data.to_csv('data/uci-heart-disease/processed.cleveland-cleansed.data', index=False)\n",
    "\n",
    "# Load the saved data for verification.\n",
    "df = pd.read_csv('data/uci-heart-disease/processed.cleveland-cleansed.data')\n",
    "df"
   ],
   "id": "c2f753c2f69246a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e409564811cc21b",
   "metadata": {},
   "source": [
    "# Ideally we should expect both classes in the target variable to have same proportion, i.e. ~148.\n",
    "len(df[\"target\"]) / 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Nevertheless, a slight risk variation can be accepted. Let's investigate if the target class in balanced.\n",
    "df['target'].value_counts()"
   ],
   "id": "f915faf0978610a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# To get the percentage proportion, let's view the normalized value counts.\n",
    "# So, the deviation in the distribution is ~4%.\n",
    "df['target'].value_counts(normalize=True)"
   ],
   "id": "173ececa7ec57f12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see the distribution of target variable's class in bar-chart.\n",
    "df['target'].value_counts().plot(kind=\"bar\", color=['steelblue', 'darksalmon']);"
   ],
   "id": "d1548e43bf8030a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's investigate which features have strong correlation with target.\n",
    "df.corr()"
   ],
   "id": "536ecfcd0cc14cac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see the correlation matrix with color intensity spectrum - the darker the blue is, the higher the correlation.\n",
    "corr_matrix = df.corr(method='pearson')\n",
    "mask = np.triu(np.ones_like(data.corr()))\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.heatmap(corr_matrix,\n",
    "            mask=mask,\n",
    "            annot=True,\n",
    "            linewidths=0.5,\n",
    "            fmt= \".2f\",\n",
    "            cmap=\"GnBu\");"
   ],
   "id": "a5cc70a160114c7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.1 Feature Correlation\n",
    "By eyeballing the chart (above), we can conclude the following from the Pearson's correlation.\n",
    "\n",
    "| Level     |   Positive   |    Negative    |\n",
    "|:----------|:------------:|:--------------:|\n",
    "| Strong    |  0.70 to 1   |  -0.70 to -1   |\n",
    "| Moderate  | 0.30 to 0.70 | -0.30 to -0.70 |\n",
    "| Weak      |  0 to 0.30   |   0 to -0.30   |\n",
    "\n",
    "If we apply the <u>general rules for classifying correlation</u> (using the table above), we observe:\n",
    "* Features have <u>only moderate correlation</u> between each other and target variable.\n",
    "#### Positive correlation - positive linear relationship\n",
    "* Six features has moderate <u>postive correlation to target</u> variable:\n",
    "1. thal (0.53)\n",
    "2. ca (0.46)\n",
    "3. oldpeak (0.42)\n",
    "4. exang (0.42)\n",
    "5. cp (0.41)\n",
    "6. slope (0.33)\n",
    "* Six features has moderate <u>positive correlation between variables</u>:\n",
    "1. oldpeak and slope (0.58)\n",
    "2. sex and thal (0.38)\n",
    "3. cp and exang (0.38)\n",
    "4. age and ca (0.36)\n",
    "5. oldpeak and thal (0.34)\n",
    "6. exang and thal (0.33)\n",
    "#### Negative correlation - negative (inverse) linear relationship\n",
    "* One feature has moderate <u>negative correlation to target</u> variable:\n",
    "1. thalach (-0.42)\n",
    "* Six features has moderate <u> negative correlation between variables</u>:\n",
    "1. age and thalach (-0.39)\n",
    "2. thalach and slope (-0.39)\n",
    "3. thalach and exang (-0.38)\n",
    "4. thalach and oldpeak (-0.35)\n",
    "2. cp and thalach (-0.34)\n",
    "3. thalach and thal (-0.27)\n",
    "4. thalach and ca (-0.27)\n",
    "\n",
    "### Further investigation needed\n",
    "We applied pearson's correlation to identify the correlation. We also need to investigate the following to ensure :\n",
    "- both variables are quantitative\n",
    "- variables are normally distributed\n",
    "- no outliers\n",
    "* Let's find the top 3 variables and investigate:\n",
    "1. oldpeak and slope (0.58)\n",
    "2. thal and target (0.53)\n",
    "3. ca and target (0.42)\n",
    "* And, one negative correlation:\n",
    "1. thalach and target (-0.42)"
   ],
   "id": "7d29b468ba3d158d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The curve is slightly right skewed. Mean and median also be slightly on the right.\n",
    "reload(helper)\n",
    "helper.draw_histogram_density_curve(df,'trestbps')"
   ],
   "id": "5a02ea0755ca8d27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['trestbps'].describe()",
   "id": "7cf4ff70e9941401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Q3 = df['trestbps'].quantile(0.75)",
   "id": "acb800f470ffdffc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8d5fd5ab34faec72",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
