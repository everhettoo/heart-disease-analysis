{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Objective\n",
    "Before building ML models using the UCI Heart-Disease dataset, the following questions are to be clarified in this stage (data exploration).\n",
    "1. What problem needs solving?\n",
    "2. What data the dataset contains?\n",
    "3. Which feature appears more important than the other?\n",
    "4. What is the expected outcome?\n",
    "\n",
    "Once, these questions are clarified, we can proceed to next stage."
   ],
   "id": "f0eb4ade433a0269"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load required libraries.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt;\n",
    "import seaborn as sns;\n",
    "from custom_libs import helper\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import models.uci_heart_disease_dataset as uci\n",
    "from models.uci_heart_disease_dataset import UCIHeartDiseaseData"
   ],
   "id": "8f21e87a43621955",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "890749f0a123e02b",
   "metadata": {},
   "source": [
    "reload(uci)\n",
    "# The 'uci_heart_disease_dataset' library was created to handle UCI dataset related matters.\n",
    "# The 'get_standard_features' method returns meaningful names in list[] and can be used in dataframe header.\n",
    "data = pd.read_csv(uci.UCIHeartDiseaseDataFile.cleveland_standard, names=uci.get_standard_features())\n",
    "\n",
    "# 303 records and 14 columns.\n",
    "data.head(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. What problem needs solving?\n",
    "<b>Classify</b> - whether a patient has heart disease based on his/her medical data.\n",
    "\n",
    "At a glance, it appears to be binary classification problem.\\\n",
    "From the data-dictionary, `Target` is the candidate for the classification. Let's investigate the variable's supportability for <u>binary classification</u> problem."
   ],
   "id": "322ef85552d321e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see what the 'Target' variable is made of.\n",
    "data.info()"
   ],
   "id": "cc0d8512f6a6ebce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# From the above, it appears that 'Target' variable has integer data-type.\n",
    "# Let's investigate further if the integer values are in binary class (1 and 0).\n",
    "data[uci.UCIHeartDiseaseData.target].value_counts()"
   ],
   "id": "e25a1afb0b274595",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observation:\n",
    "The `Target` variable cannot support binary classification since it has more than 2 values/classes.\n",
    "\n",
    "If we understood the original intention from the [data-dictionary](1.0-introduction.ipynb) and the literature:\n",
    "- Any patient with less than 50% vessel narrowing was marked as `value: 0` -- no heart disease\n",
    "- Any patient with more than 50% vessel narrowing was marked as `value: 1` -- has heart disease. This was further expanded to 1, 2, 3 and 4 based on affected major vessel.\n",
    "\n",
    "### Conclusion:\n",
    "We can safely convert this to a binary classification problem by replacing any values of target variable other than `0` to `1`. This logically simplifies that any patient with vessel narrowing more than 50% is suspected to have heart-disease (without distorting the original meaning much)."
   ],
   "id": "20a1761f4ac8c562"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert any values in target variable other than `0` to `1` - to support binary classification problem.\n",
    "# The sum of 1, 2, 3 and 4 classes should total up to 55 + 36 + 35 + 13 = 139.\n",
    "data.loc[data[uci.UCIHeartDiseaseData.target]!=0,uci.UCIHeartDiseaseData.target]=1\n",
    "data[uci.UCIHeartDiseaseData.target].value_counts()"
   ],
   "id": "cd010bc96be740b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. What data-types the dataset contains?\n",
    "We got the basic idea about the data types from the [data-dictionary](1.0-introduction.ipynb). let's investigate and verify further the content."
   ],
   "id": "14e49292b4c2276e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T03:55:45.512517Z",
     "start_time": "2024-12-24T03:55:45.508115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The dictionary indicated all processed data is in numerical format. Let's investigate.\n",
    "data.info()"
   ],
   "id": "24c19fe43fa345cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Age                    303 non-null    float64\n",
      " 1   Gender                 303 non-null    float64\n",
      " 2   Chest Pain             303 non-null    float64\n",
      " 3   BP Systolic            303 non-null    float64\n",
      " 4   Cholesterol            303 non-null    float64\n",
      " 5   Blood Sugar            303 non-null    float64\n",
      " 6   Rest ECG               303 non-null    float64\n",
      " 7   Exe. Max Heartrate     303 non-null    float64\n",
      " 8   Exe. Induced Angina    303 non-null    float64\n",
      " 9   Exe. ST Depression     303 non-null    float64\n",
      " 10  Exe. ST Segment Slope  303 non-null    float64\n",
      " 11  Major Vessels          303 non-null    object \n",
      " 12  Thalassemia            303 non-null    object \n",
      " 13  Target                 303 non-null    int64  \n",
      "dtypes: float64(11), int64(1), object(2)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T03:56:23.899598Z",
     "start_time": "2024-12-24T03:56:23.896815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# There are 11 numerical (float and int) data, and two objects ('Major Vessels' and 'Thalassemia'). This 2 objects were not documented in data-dictionary.\n",
    "# Let's check if there are for missing values (isnull/isna checks for None, NaN or NaT (datetime)).\n",
    "data.isnull().sum()"
   ],
   "id": "b982da583552187b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                      0\n",
       "Gender                   0\n",
       "Chest Pain               0\n",
       "BP Systolic              0\n",
       "Cholesterol              0\n",
       "Blood Sugar              0\n",
       "Rest ECG                 0\n",
       "Exe. Max Heartrate       0\n",
       "Exe. Induced Angina      0\n",
       "Exe. ST Depression       0\n",
       "Exe. ST Segment Slope    0\n",
       "Major Vessels            0\n",
       "Thalassemia              0\n",
       "Target                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T03:56:51.438706Z",
     "start_time": "2024-12-24T03:56:51.435141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Result shows no missing values. But why the data types for 'Major Vessels' and 'Thalassemia' are not numeric as indicated by data-dictionary?\n",
    "# Let's investigate further the two objects manually, to identify the missing values.\n",
    "for item in uci.get_standard_features():\n",
    "    d = data[item]\n",
    "    if d.dtype == 'object':\n",
    "        print(data[item].value_counts())"
   ],
   "id": "656a0cbe191c5d0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major Vessels\n",
      "0.0    176\n",
      "1.0     65\n",
      "2.0     38\n",
      "3.0     20\n",
      "?        4\n",
      "Name: count, dtype: int64\n",
      "Thalassemia\n",
      "3.0    166\n",
      "7.0    117\n",
      "6.0     18\n",
      "?        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T03:57:03.134479Z",
     "start_time": "2024-12-24T03:57:03.131071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 'Major Vessels' and 'Thalassemia' should be numerical. However, it is marked as '?'.\n",
    "# Let's investigate further on Thalassemia.\n",
    "data[uci.UCIHeartDiseaseData.thalassemia].value_counts()"
   ],
   "id": "44d78aae31062295",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thalassemia\n",
       "3.0    166\n",
       "7.0    117\n",
       "6.0     18\n",
       "?        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T03:57:11.572744Z",
     "start_time": "2024-12-24T03:57:11.566690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's check the distribution of the missing value marked as '?' in both features.\n",
    "data[(data[uci.UCIHeartDiseaseData.thalassemia]=='?') | (data[uci.UCIHeartDiseaseData.major_vessels]=='?')]"
   ],
   "id": "cd2ed89dba9f5e35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Age  Gender  Chest Pain  BP Systolic  Cholesterol  Blood Sugar  \\\n",
       "87   53.0     0.0         3.0        128.0        216.0          0.0   \n",
       "166  52.0     1.0         3.0        138.0        223.0          0.0   \n",
       "192  43.0     1.0         4.0        132.0        247.0          1.0   \n",
       "266  52.0     1.0         4.0        128.0        204.0          1.0   \n",
       "287  58.0     1.0         2.0        125.0        220.0          0.0   \n",
       "302  38.0     1.0         3.0        138.0        175.0          0.0   \n",
       "\n",
       "     Rest ECG  Exe. Max Heartrate  Exe. Induced Angina  Exe. ST Depression  \\\n",
       "87        2.0               115.0                  0.0                 0.0   \n",
       "166       0.0               169.0                  0.0                 0.0   \n",
       "192       2.0               143.0                  1.0                 0.1   \n",
       "266       0.0               156.0                  1.0                 1.0   \n",
       "287       0.0               144.0                  0.0                 0.4   \n",
       "302       0.0               173.0                  0.0                 0.0   \n",
       "\n",
       "     Exe. ST Segment Slope Major Vessels Thalassemia  Target  \n",
       "87                     1.0           0.0           ?       0  \n",
       "166                    1.0             ?         3.0       0  \n",
       "192                    2.0             ?         7.0       1  \n",
       "266                    2.0           0.0           ?       1  \n",
       "287                    2.0             ?         7.0       0  \n",
       "302                    1.0             ?         3.0       0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Chest Pain</th>\n",
       "      <th>BP Systolic</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Blood Sugar</th>\n",
       "      <th>Rest ECG</th>\n",
       "      <th>Exe. Max Heartrate</th>\n",
       "      <th>Exe. Induced Angina</th>\n",
       "      <th>Exe. ST Depression</th>\n",
       "      <th>Exe. ST Segment Slope</th>\n",
       "      <th>Major Vessels</th>\n",
       "      <th>Thalassemia</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T03:57:56.514158Z",
     "start_time": "2024-12-24T03:57:56.511232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# From above, it looks like the sum is 6, and they are disjointed (4 from 'Major Vessels' and 2 from 'Thalassemia'):\n",
    "# Let's see the overall percentage of the missing values.\n",
    "print(f'[{uci.UCIHeartDiseaseData.major_vessels}] has {round(helper.value_count(data,uci.UCIHeartDiseaseData.major_vessels,\n",
    "                                                                                '?'),2)}% of \\'?\\' values.')\n",
    "print(f'[{uci.UCIHeartDiseaseData.thalassemia}] has {round(helper.value_count(data,uci.UCIHeartDiseaseData.thalassemia,\n",
    "                                                                                '?'),2)}% of \\'?\\' values.')"
   ],
   "id": "f923a0bef9d81f6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Major Vessels] has 1.32% of '?' values.\n",
      "[Thalassemia] has 0.66% of '?' values.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observation:\n",
    "- From the investigation, it appears feature `Major Vessels` and `Thalassemia` have missing values marked as `?`.\n",
    "- Together there are 6 records (4 from `Major Vessels` and 2 from `Thalassemia`) and they are disjoint.\n",
    "- The total missing values are less than 2%.\n",
    "\n",
    "### Conclusion\n",
    "- There are ~2% missing value in the dataset, cannot impute with 'mean' since it was originally a categorical and important variable - should be dropped to avoid unnecessary data inconsistency.\n",
    "- Before dropping, other datasets (Long Beach, Hungarian and Switzerland) need to be investigated for similar issue."
   ],
   "id": "50a5566f8093fbf6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A Brief Investigation on Other Datasets",
   "id": "8263e3389569c180"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T04:06:49.542694Z",
     "start_time": "2024-12-24T04:06:49.535157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hungarian dataset\n",
    "reload(uci)\n",
    "data = pd.read_csv(uci.UCIHeartDiseaseDataFile.hungarian_standard, names=uci.get_standard_features())\n",
    "for item in uci.get_standard_features():\n",
    "    d = data[item]\n",
    "    if d.dtype == 'object':\n",
    "        print(f'[{item}] has {round(helper.value_count(data,item,'?'),2)}% of ? values.')"
   ],
   "id": "826514199d29c1dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BP Systolic] has 0.34% of ? values.\n",
      "[Cholesterol] has 7.82% of ? values.\n",
      "[Blood Sugar] has 2.72% of ? values.\n",
      "[Rest ECG] has 0.34% of ? values.\n",
      "[Exe. Max Heartrate] has 0.34% of ? values.\n",
      "[Exe. Induced Angina] has 0.34% of ? values.\n",
      "[Exe. ST Segment Slope] has 64.63% of ? values.\n",
      "[Major Vessels] has 98.98% of ? values.\n",
      "[Thalassemia] has 90.48% of ? values.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T04:06:51.380150Z",
     "start_time": "2024-12-24T04:06:51.373525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Long Beach dataset\n",
    "reload(uci)\n",
    "data = pd.read_csv(uci.UCIHeartDiseaseDataFile.longbeach_standard, names=uci.get_standard_features())\n",
    "for item in uci.get_standard_features():\n",
    "    d = data[item]\n",
    "    if d.dtype == 'object':\n",
    "        print(f'[{item}] has {round(helper.value_count(data,item,'?'),2)}% of ? values.')"
   ],
   "id": "55438b8cf1cbf196",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BP Systolic] has 28.0% of ? values.\n",
      "[Cholesterol] has 3.5% of ? values.\n",
      "[Blood Sugar] has 3.5% of ? values.\n",
      "[Exe. Max Heartrate] has 26.5% of ? values.\n",
      "[Exe. Induced Angina] has 26.5% of ? values.\n",
      "[Exe. ST Depression] has 28.0% of ? values.\n",
      "[Exe. ST Segment Slope] has 51.0% of ? values.\n",
      "[Major Vessels] has 99.0% of ? values.\n",
      "[Thalassemia] has 83.0% of ? values.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T04:06:53.140833Z",
     "start_time": "2024-12-24T04:06:53.133830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Switzerland dataset\n",
    "reload(uci)\n",
    "data = pd.read_csv(uci.UCIHeartDiseaseDataFile.switzerland_standard, names=uci.get_standard_features())\n",
    "for item in uci.get_standard_features():\n",
    "    d = data[item]\n",
    "    if d.dtype == 'object':\n",
    "        print(f'[{item}] has {round(helper.value_count(data,item,'?'),2)}% of ? values.')"
   ],
   "id": "96d7b815107a2ff6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BP Systolic] has 1.63% of ? values.\n",
      "[Blood Sugar] has 60.98% of ? values.\n",
      "[Rest ECG] has 0.81% of ? values.\n",
      "[Exe. Max Heartrate] has 0.81% of ? values.\n",
      "[Exe. Induced Angina] has 0.81% of ? values.\n",
      "[Exe. ST Depression] has 4.88% of ? values.\n",
      "[Exe. ST Segment Slope] has 13.82% of ? values.\n",
      "[Major Vessels] has 95.93% of ? values.\n",
      "[Thalassemia] has 42.28% of ? values.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Important Notice!!!\n",
    "As can be seen from the above brief investigations, other datasets (Long Beach, Hungarian and Switzerland) also contains the `?` character in many of its variables.\n",
    "\n",
    "This raises a big question on the validity of the processed dataset! This requires a thorough investigation!\n",
    "\n",
    "### Investigation Summary:\n",
    "- The processed datasets (Long Beach, Hungarian and Switzerland) was supposed to be clean and usable. Instead, 68% (621/920) of the UCI dataset has missing values which was marked with '?'. This was investigated here [processed dataset investigation](2.1-uci-processed-dataset-investigation.ipynb)\n",
    "- Since unable to recover data from the processed dataset, preprocessing the original (raw) data files was the subsequent approach. However, as seen here [raw dataset investigation](2.1-uci-processed-dataset-investigation.ipynb), the '?' mark actually originated from the raw file, it had a different value, which was -9 (integer).\n",
    "- 2/617 was salvaged and saved into `processed.salvaged.data` file to be concatenated into the current DataFrame"
   ],
   "id": "598b7879472d5754"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: Concatenate salvaged data into current data-frame",
   "id": "531d049798065a89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop records for feature `ca` and `thal` that are `?` The new total records are 303 - 6 = 297.\n",
    "filtered = data[(data['thal'] == '?') | (data['ca'] == '?')].index\n",
    "data.drop(filtered, inplace=True)\n",
    "data.shape"
   ],
   "id": "52fa0f5d0189f5da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Does the dataset have empty columns (features)?\n",
    "Now that we have verified the data consistencies, let's <u>investigate if any data is missing in the dataset</u>."
   ],
   "id": "eddf09a4e6f44e1f"
  },
  {
   "cell_type": "code",
   "id": "2c98fef25a77d2a6",
   "metadata": {},
   "source": [
    "# No missing data. isnull and isna is the same, checking for None, NaN or NaT (datetime)\n",
    "data.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Is the dataset sufficient for building the model(s)?\n",
    "Now that the dataset was cleansed, let's explore the data for further analysis (with graphs when needed)."
   ],
   "id": "9a4a250b4589c58b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's save a copy of the cleansed dataset for building models.\n",
    "data.to_csv('data/uci-heart-disease/processed.cleveland-cleansed.data', index=False)\n",
    "\n",
    "# Load the saved data for verification.\n",
    "df = pd.read_csv('data/uci-heart-disease/processed.cleveland-cleansed.data')\n",
    "df"
   ],
   "id": "c2f753c2f69246a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e409564811cc21b",
   "metadata": {},
   "source": [
    "# Ideally we should expect both classes in the target variable to have same proportion, i.e. ~148.\n",
    "len(df[\"target\"]) / 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Nevertheless, a slight risk variation can be accepted. Let's investigate if the target class in balanced.\n",
    "df['target'].value_counts()"
   ],
   "id": "f915faf0978610a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# To get the percentage proportion, let's view the normalized value counts.\n",
    "# So, the deviation in the distribution is ~4%.\n",
    "df['target'].value_counts(normalize=True)"
   ],
   "id": "173ececa7ec57f12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see the distribution of target variable's class in bar-chart.\n",
    "df['target'].value_counts().plot(kind=\"bar\", color=['steelblue', 'darksalmon']);"
   ],
   "id": "d1548e43bf8030a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's investigate which features have strong correlation with target.\n",
    "df.corr()"
   ],
   "id": "536ecfcd0cc14cac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's see the correlation matrix with color intensity spectrum - the darker the blue is, the higher the correlation.\n",
    "corr_matrix = df.corr(method='pearson')\n",
    "mask = np.triu(np.ones_like(data.corr()))\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.heatmap(corr_matrix,\n",
    "            mask=mask,\n",
    "            annot=True,\n",
    "            linewidths=0.5,\n",
    "            fmt= \".2f\",\n",
    "            cmap=\"GnBu\");"
   ],
   "id": "a5cc70a160114c7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.1 Feature Correlation\n",
    "By eyeballing the chart (above), we can conclude the following from the Pearson's correlation.\n",
    "\n",
    "| Level     |   Positive   |    Negative    |\n",
    "|:----------|:------------:|:--------------:|\n",
    "| Strong    |  0.70 to 1   |  -0.70 to -1   |\n",
    "| Moderate  | 0.30 to 0.70 | -0.30 to -0.70 |\n",
    "| Weak      |  0 to 0.30   |   0 to -0.30   |\n",
    "\n",
    "If we apply the <u>general rules for classifying correlation</u> (using the table above), we observe:\n",
    "* Features have <u>only moderate correlation</u> between each other and target variable.\n",
    "#### Positive correlation - positive linear relationship\n",
    "* Six features has moderate <u>postive correlation to target</u> variable:\n",
    "1. thal (0.53)\n",
    "2. ca (0.46)\n",
    "3. oldpeak (0.42)\n",
    "4. exang (0.42)\n",
    "5. cp (0.41)\n",
    "6. slope (0.33)\n",
    "* Six features has moderate <u>positive correlation between variables</u>:\n",
    "1. oldpeak and slope (0.58)\n",
    "2. sex and thal (0.38)\n",
    "3. cp and exang (0.38)\n",
    "4. age and ca (0.36)\n",
    "5. oldpeak and thal (0.34)\n",
    "6. exang and thal (0.33)\n",
    "#### Negative correlation - negative (inverse) linear relationship\n",
    "* One feature has moderate <u>negative correlation to target</u> variable:\n",
    "1. thalach (-0.42)\n",
    "* Six features has moderate <u> negative correlation between variables</u>:\n",
    "1. age and thalach (-0.39)\n",
    "2. thalach and slope (-0.39)\n",
    "3. thalach and exang (-0.38)\n",
    "4. thalach and oldpeak (-0.35)\n",
    "2. cp and thalach (-0.34)\n",
    "3. thalach and thal (-0.27)\n",
    "4. thalach and ca (-0.27)\n",
    "\n",
    "### Further investigation needed\n",
    "We applied pearson's correlation to identify the correlation. We also need to investigate the following to ensure :\n",
    "- both variables are quantitative\n",
    "- variables are normally distributed\n",
    "- no outliers\n",
    "* Let's find the top 3 variables and investigate:\n",
    "1. oldpeak and slope (0.58)\n",
    "2. thal and target (0.53)\n",
    "3. ca and target (0.42)\n",
    "* And, one negative correlation:\n",
    "1. thalach and target (-0.42)"
   ],
   "id": "7d29b468ba3d158d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The curve is slightly right skewed. Mean and median also be slightly on the right.\n",
    "reload(helper)\n",
    "helper.draw_histogram_density_curve(df,'trestbps')"
   ],
   "id": "5a02ea0755ca8d27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['trestbps'].describe()",
   "id": "7cf4ff70e9941401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Q3 = df['trestbps'].quantile(0.75)",
   "id": "acb800f470ffdffc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8d5fd5ab34faec72",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
