{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4354665ec71d95ae",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "Few heart disease dataset can be found in Kaggle. Mostly, the origin can be traced to the UCI Heart Disease dataset. Quite often, the data in Kaggle found oversampled, distorted or features are transposed and untraceable.\n",
    "\n",
    "In order to understand the underlying problem that originally the author (Dr. Robert Detrano) intended to solve, getting the dataset from the original source can be reliable.\n",
    "\n",
    "The original <a href='https://archive.ics.uci.edu/dataset/45/heart+disease'>UCI Heart Disease</a> dataset contains 4 data files collected from the four following locations, from 1981 to 1987:\n",
    "\n",
    "1. Cleveland Clinic Foundation (cleveland.data), 1981 - 1984\n",
    "2. Hungarian Institute of Cardiology, Budapest (hungarian.data), 1983 - 1987\n",
    "3. V.A. Medical Center, Long Beach, CA (long-beach-va.data), 1984 - 1987\n",
    "4. University Hospital, Zurich, Switzerland (switzerland.data), 1985\n",
    "\n",
    "# 2. Acknowledgements\n",
    "It is a requirement to include the names of the principal investigator responsible for the data collection at each institution when the dataset is being used.  They would be:\n",
    "\n",
    "1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n",
    "2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n",
    "3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n",
    "4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.\n",
    "\n",
    "# 3. Background\n",
    "In this section, following a brief necessary history, <u>the files used in this study and its relationship is discussed</u>:\n",
    "## 3.1 Dataset Content\n",
    "After the original dataset was downloaded, few files are extracted in the `/heart-disease` directory. To investigate the contents of the dataset, the `cat` cmd can be used on `Index` file."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T14:15:16.176117Z",
     "start_time": "2024-12-06T14:15:16.028231Z"
    }
   },
   "cell_type": "code",
   "source": "!cat data/uci-heart-disease/Index",
   "id": "e6179ef89aaed835",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of heart-disease\r\n",
      "\r\n",
      "02 Dec 1996      644 Index\r\n",
      "02 Dec 1996      dir costs\r\n",
      "23 Jul 1996    11058 reprocessed.hungarian.data\r\n",
      "14 Aug 1991     6737 bak\r\n",
      "14 Aug 1991    10263 processed.hungarian.data\r\n",
      "14 Aug 1991     4109 processed.switzerland.data\r\n",
      "14 Aug 1991     6737 processed.va.data\r\n",
      "20 Jul 1990   389771 new.data\r\n",
      "06 Jun 1990    10060 heart-disease.names\r\n",
      "15 Mar 1990      587 ask-detrano\r\n",
      "15 Mar 1990    62192 hungarian.data\r\n",
      "13 Mar 1990    23941 cleve.mod\r\n",
      "06 Mar 1990    18461 processed.cleveland.data\r\n",
      "31 Jan 1990      407 WARNING\r\n",
      "31 Jan 1990    60669 cleveland.data\r\n",
      "30 May 1989    39892 long-beach-va.data\r\n",
      "30 May 1989    24674 switzerland.data\r\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.2 Dataset History\n",
    "The author used the raw `cleveland.data` file to build a model to predict the other three datasets:\n",
    "- hungarian.data\n",
    "- long-beach-va.data\n",
    "- switzerland.data\n",
    "\n",
    "For unknown reasons, the `cleveland.data` got corrupted during upload and became beyond recoverable. This is indicated in the `WARNING` file (`cat` cmd can be used to investigate file)."
   ],
   "id": "e24152b2739d43e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T14:17:20.460330Z",
     "start_time": "2024-12-06T14:17:20.329343Z"
    }
   },
   "cell_type": "code",
   "source": "!cat data/uci-heart-disease/WARNING",
   "id": "cfb5aab52dd8229",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file cleveland.data has been unfortunately messed up when we lost\r\n",
      "node cip2 and loaded the file on node ics.  The file processed.cleveland.data\r\n",
      "seems to be in good shape and is useable (for the 14 attributes situation).\r\n",
      "I'll clean up cleveland.data as soon as possible.\r\n",
      "\r\n",
      "Bad news: my original copy of the database appears to be corrupted.\r\n",
      "I'll have to go back to the donor to get a new copy.\r\n",
      "\r\n",
      "David Aha\r\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.3 Investigating the Corruption\n",
    "Though other raw data files (hungarian.data, long-beach-va.data and switzerland.data) are in `ascii` format, the `cleveland.data` file found to be in binary format and indicates uploading disruption. This can be investigated with `file -I` cmd."
   ],
   "id": "2f9a6ddf136d996c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T14:19:57.792143Z",
     "start_time": "2024-12-06T14:19:57.654962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Originally, 'text/plain' protocol was used to upload (transfer) with charset=us-ascii for encoding.\n",
    "!file -I data/uci-heart-disease/hungarian.data"
   ],
   "id": "9394d914d625138f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/uci-heart-disease/hungarian.data: text/plain; charset=us-ascii\r\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "193f84d4c578e7da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T14:22:28.819100Z",
     "start_time": "2024-12-06T14:22:28.685522Z"
    }
   },
   "source": [
    "# Meanwhile, for the corrupted 'cleveland.data file, 'octet-stream' protocol was used to upload (transfer) with charset=binary for encoding.\n",
    "!file -I data/uci-heart-disease/cleveland.data"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/uci-heart-disease/cleveland.data: application/octet-stream; charset=binary\r\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Though the first half of `cleveland.data` file seem in `ascii` format, when `tail -n 100 cleveland.data` was used, the second half of the file appears in binary encoding. This can be observed with gibberish characters.",
   "id": "64eb230a042b019d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T14:23:21.730605Z",
     "start_time": "2024-12-06T14:23:21.599010Z"
    }
   },
   "cell_type": "code",
   "source": "!tail -n 100 data/uci-heart-disease/cleveland.data",
   "id": "553d540c25180997",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-21 1 1 1 1\r\n",
      "1 1 1\r\n",
      "1 1 -9 -9 n1 1 1\r\n",
      "1 1 -9 -9 n1\u0000\u000010 0 0 1 50 0 0 1 5020 0 -9-9 20  1 -9 -9 -9\r\n",
      "-9 3 1382 -9-9 9\r\n",
      "-9 9\r\n",
      "- 84 0 1  84 0 1  3 -9 2050 701 0 1 01 0 1 01-9 -9 -9\r\n",
      "-9 4 136-9 -9 -9\r\n",
      "-9 4 136-9\r\n",
      "1 9\r\n",
      "1 92 -9 1 2 1 10 81 0 0 81 0 0\u0000\u0000060 360 36\u0000\u000067.5 3.2 09 7 -9 7 -9\u0000\u0000980 1 0\r\n",
      "0 1\r\n",
      "1 1 -7 177 177\u0000\u000070 0\r\n",
      "0.2 0 0\r\n",
      "0.2 0 24 81 0 0 01 0 0 01\u0000\u000015 -9 5 1 1 1\r\n",
      "1 1 - 1 -9 1 1 1 1 1\r\n",
      "1 10 80 10 80 10-9 3 --9 3 --\u0000\u0000-60 60 60 13\u0000\u0000\u0000 0 1  0 1  \u0000\u0000 \u0000\u0000\u0000 1 1\r\n",
      "1 1 -9 7\r\n",
      "117\r\n",
      "1174 0 13 12\r\n",
      "4 11 -9 -9 -9\r\n",
      "-9 -9 -9 3 -9 -9 -9 1 -9 1\r\n",
      "-9 0 55  0 55  \u0000\u0000 -9 0 2 19 -9\r\n",
      "-9 4 130 5 0 -9 -9 -8 808 808 30\r\n",
      "0  -9 -9 12\r\n",
      "6 2 1 1 1\r\n",
      "7 2 1 1 1\r\n",
      "7  1 32<<<\u0000\u0000<\r\n",
      "5  26705 64 1 -9  6\r\n",
      "891 0ï¿½40 0 1940 0 194 2 -9 22 2 -9 22 \u0000\u0000 \u0000\u0000 \u0000\u0000 \u0000\u0000\u0000\u0000 60 0  60 0  \u0000\u0000 2116 3 -93 1 -9 -9 n\r\n",
      "-9 1 -9 1 1 1 1 1\r\n",
      "90 0 -90 0 -92 80 1 1 0 18 1585 15 -9 7 -9 -70 1070 107e\r\n",
      "fff -9 -9 name\r\n",
      "89 81 0 1  81 0 1  \u0000\u0000 7 17 name\r\n",
      "23 name\r\n",
      "23 \u0000\u0000  15 1 1 -9 -9 -9\r\n",
      "-9 -7 2449494811 1 12 1282 1282\u0000\u00002-9 -9 -9 3 -0 1450 1450\u0000\u00005 8626 84 --9 name\r\n",
      "75-9 name\r\n",
      "75-\u0000\u0000-\u0000\u0000\u000058 8658 865\u0000\u00005\u0000\u0000\u00004 1 2 0\r\n",
      "3 -9 5-9 5--9 name\r\n",
      "81 6 2 1 2 1 0 -9 0 0 125 2 1 -9 10 1 -9 10 \u0000\u0000 7 67 671\r\n",
      "-9 1 -66 66 6\u0000\u00006\u0000\u0000\u00009 1 -9 1 1 1 9 1 -9 1 1 1 9\u0000\u000099.6 1 -9 -9 26 8426 8422 1 -9 -9 -9 -9\r\n",
      "-9 -9 -9 7 -9 3 -9 83 -9 830 0\r\n",
      "0.2 00 0\r\n",
      "0.2 00\u0000\u0000\u0000\u0000\u0000\u0000\u00000 1 9  -9 1014 685 3 3539 0 680 0\r\n",
      "0 0\r\n",
      "06363660 1 23\u0000\u0000\u00003 7\r\n",
      "14-9 -9 -9 12\r\n",
      "1-9 20-9 20-\u0000\u0000-\u0000\u0000\u000051 0 541 -9 1\r\n",
      "-9  62 133 13  81 0 1 81 0 1 9 3 9 3 94 1\r\n",
      "4 1\r\n",
      "4\u0000\u000042242242\u0000\u000028 1 111\r\n",
      "182 1355 0 465 0 4659 1 -9 2081 681 6880 71 1 1 1\r\n",
      "1 1 -9 1 1 1 1\r\n",
      "1 1 -9 1-9 -9 -9 3 -0-9 -9 -9 12\r\n",
      "89 169 169\u0000\u00009\u0000\u0000\u0000 -9 name\r\n",
      "12 2829 8229 8223 13 0 0 0 1 70 0 0 1 707\r\n",
      "167\r\n",
      "16781 481 487 854 1 2 9 12 9 12\u0000\u00002-9 1\r\n",
      "-9 1 -9 2 158 658 65\u0000\u00005.7 9 3 -9 -99 3 -9 -99 1 -9 -9 name\r\n",
      "237\r\n",
      "1116 83 16 83 1\u0000\u000011 1 6  125 125 \u0000\u0000  -9 10\r\n",
      "17 40  40  1 1 1 1 1\r\n",
      "1 11 1 1 1 1\r\n",
      "1 11\u0000\u00001\u0000\u0000\u0000\u0000\u0000\u00000\r\n",
      "0 -9 1 2 1 -9 0 27\r\n",
      "111 1 -9 -9 -9\r\n",
      "-9 4 3 85 3 85 3\u0000\u00003\u0000\u0000\u0000 1\r\n",
      "-9 1 -9 1 1\r\n",
      "-9 1 -9 1  81 0 1 1 1 - 81 0 1 1 1 -  81 04 1084 1084\u0000\u0000400 1100 110\u0000\u0000040e\r\n",
      "4650 12 80 0 0 70 0 -9 -9 103 0 -9 -9 -9\r\n",
      "3 0 -9 -9 -9\r\n",
      "3\u0000\u00003\u0000\u0000\u00000\r\n",
      "0 -9 1 0 1 1 1 - 234\r\n",
      "11 80 0\r\n",
      "0 -1 -9 1 04 0 -9 -9 \r\n",
      "23 89 -9 -9 6\r\n",
      "9 -9 -9 6\r\n",
      "94 1 -9 -9 -9\r\n",
      "-9 357 -57 -51 1 -9 1 1 1\r\n",
      "1 1 1 1 1\r\n",
      "1 1 1 -9 1 1 1 1 1\r\n",
      "1 1 -9 -90 0\r\n",
      "0 1 -4 729 1\r\n",
      "-9 1 -9 1 1 1 1 19 1\r\n",
      "-9 1 -9 1 1 1 1 19 2 1 0\r\n",
      "0 - 0\r\n",
      "0 - \r\n",
      "23 8\r\n",
      "13165 0 -965 0 -96\u0000\u00006 1 -9 -9 -9\r\n",
      "-9 3 138 81 0\r\n",
      "1 0 0.7 -9 -9 name\r\n",
      "9-9 -9 name\r\n",
      "9-\u0000\u0000-5 2 -9 26 -26 -2\u0000\u00002\u0000\u0000\u00006 0 -9 -6 0 -9 -6\u0000\u00006\u0000\u0000\u0000\u0000\u0000\u00009 0 6584 0\r\n",
      "1 84 0\r\n",
      "1 8\u0000\u000088 -9 4016 8216 8216 788 0 -9 -9 -9\r\n",
      "-0 0 0 1 9 -9 130 80 0 130 80 0 1\u0000\u00001\r\n",
      "-9 3 1h9 1 -9 -9 -9\r\n",
      "-9 3\u0000\u0000 -9 -9 -9\r\n",
      "-9 -9 -9 3 -9 -4 1 1"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "6b41a81bd892b61a",
   "metadata": {},
   "source": [
    "## 3.4 Processed Files as Alternatives\n",
    "So, that was the necessary history (a mystery perhaps) - to understand the original (raw) `cleveland.data` file was never available for preprocessing and no attempts of re-reloading the corrupted file was seen ever since. Alternatively, a set of processed files were made available for working on this dataset.\n",
    "\n",
    "The original (raw) file has 76 features (is enclosed in `Data Dictionary` section). Meanwhile, the processed file has only 14 of them. The author in his <a href='International application of a new probability algorithm for the diagnosis of coronary artery disease.'> initial paper</a> written in 1989, indicated that he only needs the 13 features to build prediction model (of course 14<sup>th</sup> is the target variable).\n",
    "\n",
    "The table below shows the relationship of the original (raw) and processed files' dataset.\n",
    "#### Original (raw)\n",
    "| Filename                   | Records (Rows) | Features (Cols) |\n",
    "|:---------------------------|:--------------:|:---------------:|\n",
    "| cleveland.data             |      303       |       76        |\n",
    "| hungarian.data             |      294       |       76        |\n",
    "| long-beach-va.data         |      200       |       76        |\n",
    "| switzerland.data           |      123       |       76        |\n",
    "\n",
    "#### Processed\n",
    "| Filename                   | Records (Rows) | Features (Cols) |\n",
    "|:---------------------------|:--------------:|:---------------:|\n",
    "| processed.cleveland.data   |      303       |       14        |\n",
    "| processed.hungarian.data   |      294       |       14        |\n",
    "| processed.va.data          |      200       |       14        |\n",
    "| processed.switzerland.data |      123       |       14        |\n",
    "\n",
    "<br>\n",
    "This processed dataset's dimension can be verified using pandas:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T09:46:52.045403Z",
     "start_time": "2024-12-06T09:46:52.035226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Headers are described in Data Dictionary section.\n",
    "header =['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "data = pd.read_csv('data/uci-heart-disease/processed.cleveland.data', names=header)\n",
    "data.head(5)"
   ],
   "id": "d29789a317edb6bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  num  \n",
       "0    3.0  0.0  6.0    0  \n",
       "1    2.0  3.0  3.0    2  \n",
       "2    2.0  2.0  7.0    1  \n",
       "3    3.0  0.0  3.0    0  \n",
       "4    1.0  0.0  3.0    0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T15:02:29.572992Z",
     "start_time": "2024-12-06T15:02:29.569681Z"
    }
   },
   "cell_type": "code",
   "source": "data.shape",
   "id": "9ca591ccf757ed50",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4. Data Dictionary\n",
    "In the original journal, the author describes that he only needed the 13 variables (features) to predict heart disease in a patient based on the 14<sup>th</sup> variable, which is the target variable.\n",
    "\n",
    "So, he dropped all other 62 features, making only 14 variables available in the processed datasets, both for model building and testing.\n",
    "\n",
    "The detail documentation can be found in the `heart-disease.namaes` file."
   ],
   "id": "4135fb7b61f2c405"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T15:09:36.604492Z",
     "start_time": "2024-12-06T15:09:36.471322Z"
    }
   },
   "cell_type": "code",
   "source": "!cat data/uci-heart-disease/heart-disease.names",
   "id": "586e3e53b09f89cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publication Request: \r\n",
      "   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\n",
      "   This file describes the contents of the heart-disease directory.\r\n",
      "\r\n",
      "   This directory contains 4 databases concerning heart disease diagnosis.\r\n",
      "   All attributes are numeric-valued.  The data was collected from the\r\n",
      "   four following locations:\r\n",
      "\r\n",
      "     1. Cleveland Clinic Foundation (cleveland.data)\r\n",
      "     2. Hungarian Institute of Cardiology, Budapest (hungarian.data)\r\n",
      "     3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)\r\n",
      "     4. University Hospital, Zurich, Switzerland (switzerland.data)\r\n",
      "\r\n",
      "   Each database has the same instance format.  While the databases have 76\r\n",
      "   raw attributes, only 14 of them are actually used.  Thus I've taken the\r\n",
      "   liberty of making 2 copies of each database: one with all the attributes\r\n",
      "   and 1 with the 14 attributes actually used in past experiments.\r\n",
      "\r\n",
      "   The authors of the databases have requested:\r\n",
      "\r\n",
      "      ...that any publications resulting from the use of the data include the \r\n",
      "      names of the principal investigator responsible for the data collection\r\n",
      "      at each institution.  They would be:\r\n",
      "\r\n",
      "       1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\r\n",
      "       2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\r\n",
      "       3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\r\n",
      "       4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\r\n",
      "\t  Robert Detrano, M.D., Ph.D.\r\n",
      "\r\n",
      "   Thanks in advance for abiding by this request.\r\n",
      "\r\n",
      "   David Aha\r\n",
      "   July 22, 1988\r\n",
      "   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\n",
      "\r\n",
      "1. Title: Heart Disease Databases\r\n",
      "\r\n",
      "2. Source Information:\r\n",
      "   (a) Creators: \r\n",
      "       -- 1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\r\n",
      "       -- 2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\r\n",
      "       -- 3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\r\n",
      "       -- 4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\r\n",
      "             Robert Detrano, M.D., Ph.D.\r\n",
      "   (b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   \r\n",
      "   (c) Date: July, 1988\r\n",
      "\r\n",
      "3. Past Usage:\r\n",
      "    1. Detrano,~R., Janosi,~A., Steinbrunn,~W., Pfisterer,~M., Schmid,~J.,\r\n",
      "       Sandhu,~S., Guppy,~K., Lee,~S., \\& Froelicher,~V. (1989).  {\\it \r\n",
      "       International application of a new probability algorithm for the \r\n",
      "       diagnosis of coronary artery disease.}  {\\it American Journal of \r\n",
      "       Cardiology}, {\\it 64},304--310.\r\n",
      "       -- International Probability Analysis \r\n",
      "       -- Address: Robert Detrano, M.D.\r\n",
      "                   Cardiology 111-C\r\n",
      "                   V.A. Medical Center\r\n",
      "                   5901 E. 7th Street\r\n",
      "                   Long Beach, CA 90028\r\n",
      "       -- Results in percent accuracy: (for 0.5 probability threshold)\r\n",
      "             Data Name:  CDF    CADENZA\r\n",
      "          -- Hungarian   77     74\r\n",
      "             Long beach  79     77\r\n",
      "             Swiss       81     81\r\n",
      "          -- Approximately a 77% correct classification accuracy with a\r\n",
      "             logistic-regression-derived discriminant function\r\n",
      "    2. David W. Aha & Dennis Kibler\r\n",
      "       -- \r\n",
      "          \r\n",
      "          \r\n",
      "          -- Instance-based prediction of heart-disease presence with the \r\n",
      "             Cleveland database\r\n",
      "             -- NTgrowth: 77.0% accuracy\r\n",
      "             --       C4: 74.8% accuracy\r\n",
      "    3. John Gennari\r\n",
      "       -- Gennari, J.~H., Langley, P, \\& Fisher, D. (1989). Models of\r\n",
      "          incremental concept formation. {\\it Artificial Intelligence, 40},\r\n",
      "          11--61.\r\n",
      "       -- Results: \r\n",
      "          -- The CLASSIT conceptual clustering system achieved a 78.9% accuracy\r\n",
      "             on the Cleveland database.\r\n",
      "\r\n",
      "4. Relevant Information:\r\n",
      "     This database contains 76 attributes, but all published experiments\r\n",
      "     refer to using a subset of 14 of them.  In particular, the Cleveland\r\n",
      "     database is the only one that has been used by ML researchers to \r\n",
      "     this date.  The \"goal\" field refers to the presence of heart disease\r\n",
      "     in the patient.  It is integer valued from 0 (no presence) to 4.\r\n",
      "     Experiments with the Cleveland database have concentrated on simply\r\n",
      "     attempting to distinguish presence (values 1,2,3,4) from absence (value\r\n",
      "     0).  \r\n",
      "   \r\n",
      "     The names and social security numbers of the patients were recently \r\n",
      "     removed from the database, replaced with dummy values.\r\n",
      "\r\n",
      "     One file has been \"processed\", that one containing the Cleveland \r\n",
      "     database.  All four unprocessed files also exist in this directory.\r\n",
      "    \r\n",
      "5. Number of Instances: \r\n",
      "        Database:    # of instances:\r\n",
      "          Cleveland: 303\r\n",
      "          Hungarian: 294\r\n",
      "        Switzerland: 123\r\n",
      "      Long Beach VA: 200\r\n",
      "\r\n",
      "6. Number of Attributes: 76 (including the predicted attribute)\r\n",
      "\r\n",
      "7. Attribute Information:\r\n",
      "   -- Only 14 used\r\n",
      "      -- 1. #3  (age)       \r\n",
      "      -- 2. #4  (sex)       \r\n",
      "      -- 3. #9  (cp)        \r\n",
      "      -- 4. #10 (trestbps)  \r\n",
      "      -- 5. #12 (chol)      \r\n",
      "      -- 6. #16 (fbs)       \r\n",
      "      -- 7. #19 (restecg)   \r\n",
      "      -- 8. #32 (thalach)   \r\n",
      "      -- 9. #38 (exang)     \r\n",
      "      -- 10. #40 (oldpeak)   \r\n",
      "      -- 11. #41 (slope)     \r\n",
      "      -- 12. #44 (ca)        \r\n",
      "      -- 13. #51 (thal)      \r\n",
      "      -- 14. #58 (num)       (the predicted attribute)\r\n",
      "\r\n",
      "   -- Complete attribute documentation:\r\n",
      "      1 id: patient identification number\r\n",
      "      2 ccf: social security number (I replaced this with a dummy value of 0)\r\n",
      "      3 age: age in years\r\n",
      "      4 sex: sex (1 = male; 0 = female)\r\n",
      "      5 painloc: chest pain location (1 = substernal; 0 = otherwise)\r\n",
      "      6 painexer (1 = provoked by exertion; 0 = otherwise)\r\n",
      "      7 relrest (1 = relieved after rest; 0 = otherwise)\r\n",
      "      8 pncaden (sum of 5, 6, and 7)\r\n",
      "      9 cp: chest pain type\r\n",
      "        -- Value 1: typical angina\r\n",
      "        -- Value 2: atypical angina\r\n",
      "        -- Value 3: non-anginal pain\r\n",
      "        -- Value 4: asymptomatic\r\n",
      "     10 trestbps: resting blood pressure (in mm Hg on admission to the \r\n",
      "        hospital)\r\n",
      "     11 htn\r\n",
      "     12 chol: serum cholestoral in mg/dl\r\n",
      "     13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\r\n",
      "     14 cigs (cigarettes per day)\r\n",
      "     15 years (number of years as a smoker)\r\n",
      "     16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\r\n",
      "     17 dm (1 = history of diabetes; 0 = no such history)\r\n",
      "     18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\r\n",
      "     19 restecg: resting electrocardiographic results\r\n",
      "        -- Value 0: normal\r\n",
      "        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \r\n",
      "                    elevation or depression of > 0.05 mV)\r\n",
      "        -- Value 2: showing probable or definite left ventricular hypertrophy\r\n",
      "                    by Estes' criteria\r\n",
      "     20 ekgmo (month of exercise ECG reading)\r\n",
      "     21 ekgday(day of exercise ECG reading)\r\n",
      "     22 ekgyr (year of exercise ECG reading)\r\n",
      "     23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\r\n",
      "     24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\r\n",
      "     25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\r\n",
      "     26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\r\n",
      "     27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\r\n",
      "     28 proto: exercise protocol\r\n",
      "          1 = Bruce     \r\n",
      "          2 = Kottus\r\n",
      "          3 = McHenry\r\n",
      "          4 = fast Balke\r\n",
      "          5 = Balke\r\n",
      "          6 = Noughton \r\n",
      "          7 = bike 150 kpa min/min  (Not sure if \"kpa min/min\" is what was \r\n",
      "              written!)\r\n",
      "          8 = bike 125 kpa min/min  \r\n",
      "          9 = bike 100 kpa min/min\r\n",
      "         10 = bike 75 kpa min/min\r\n",
      "         11 = bike 50 kpa min/min\r\n",
      "         12 = arm ergometer\r\n",
      "     29 thaldur: duration of exercise test in minutes\r\n",
      "     30 thaltime: time when ST measure depression was noted\r\n",
      "     31 met: mets achieved\r\n",
      "     32 thalach: maximum heart rate achieved\r\n",
      "     33 thalrest: resting heart rate\r\n",
      "     34 tpeakbps: peak exercise blood pressure (first of 2 parts)\r\n",
      "     35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\r\n",
      "     36 dummy\r\n",
      "     37 trestbpd: resting blood pressure\r\n",
      "     38 exang: exercise induced angina (1 = yes; 0 = no)\r\n",
      "     39 xhypo: (1 = yes; 0 = no)\r\n",
      "     40 oldpeak = ST depression induced by exercise relative to rest\r\n",
      "     41 slope: the slope of the peak exercise ST segment\r\n",
      "        -- Value 1: upsloping\r\n",
      "        -- Value 2: flat\r\n",
      "        -- Value 3: downsloping\r\n",
      "     42 rldv5: height at rest\r\n",
      "     43 rldv5e: height at peak exercise\r\n",
      "     44 ca: number of major vessels (0-3) colored by flourosopy\r\n",
      "     45 restckm: irrelevant\r\n",
      "     46 exerckm: irrelevant\r\n",
      "     47 restef: rest raidonuclid (sp?) ejection fraction\r\n",
      "     48 restwm: rest wall (sp?) motion abnormality\r\n",
      "        0 = none\r\n",
      "        1 = mild or moderate\r\n",
      "        2 = moderate or severe\r\n",
      "        3 = akinesis or dyskmem (sp?)\r\n",
      "     49 exeref: exercise radinalid (sp?) ejection fraction\r\n",
      "     50 exerwm: exercise wall (sp?) motion \r\n",
      "     51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\r\n",
      "     52 thalsev: not used\r\n",
      "     53 thalpul: not used\r\n",
      "     54 earlobe: not used\r\n",
      "     55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\r\n",
      "     56 cday: day of cardiac cath (sp?)\r\n",
      "     57 cyr: year of cardiac cath (sp?)\r\n",
      "     58 num: diagnosis of heart disease (angiographic disease status)\r\n",
      "        -- Value 0: < 50% diameter narrowing\r\n",
      "        -- Value 1: > 50% diameter narrowing\r\n",
      "        (in any major vessel: attributes 59 through 68 are vessels)\r\n",
      "     59 lmt\r\n",
      "     60 ladprox\r\n",
      "     61 laddist\r\n",
      "     62 diag\r\n",
      "     63 cxmain\r\n",
      "     64 ramus\r\n",
      "     65 om1\r\n",
      "     66 om2\r\n",
      "     67 rcaprox\r\n",
      "     68 rcadist\r\n",
      "     69 lvx1: not used\r\n",
      "     70 lvx2: not used\r\n",
      "     71 lvx3: not used\r\n",
      "     72 lvx4: not used\r\n",
      "     73 lvf: not used\r\n",
      "     74 cathef: not used\r\n",
      "     75 junk: not used\r\n",
      "     76 name: last name of patient \r\n",
      "\t(I replaced this with the dummy string \"name\")\r\n",
      "\r\n",
      "9. Missing Attribute Values: Several.  Distinguished with value -9.0.\r\n",
      "\r\n",
      "10. Class Distribution:\r\n",
      "        Database:      0   1   2   3   4 Total\r\n",
      "          Cleveland: 164  55  36  35  13   303\r\n",
      "          Hungarian: 188  37  26  28  15   294\r\n",
      "        Switzerland:   8  48  32  30   5   123\r\n",
      "      Long Beach VA:  51  56  41  42  10   200\r\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
